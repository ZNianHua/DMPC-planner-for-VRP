{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traci\n",
    "import random\n",
    "import sumolib\n",
    "import os\n",
    "import collections\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import traci\n",
    "import time\n",
    "from pyscipopt import Model\n",
    "import pickle\n",
    "import itertools\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于SUMO地图文件（.net.xml）生成图，并随机初始化起点和多个终点，生成剪枝后的子图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_net_to_digraph_simple(net):\n",
    "    # 创建一个有向图\n",
    "    G = nx.DiGraph() \n",
    "    # 遍历所有边\n",
    "    for edge in net.getEdges():\n",
    "        # 遍历边的所有车道\n",
    "        for outgoing_edge in edge.getOutgoing():\n",
    "            segment_length=edge.getLength()\n",
    "            segment_speed = edge.getSpeed()\n",
    "            from_edge_id=edge.getID()\n",
    "            to_edge_id=outgoing_edge.getID()\n",
    "            G.add_edge(from_edge_id, to_edge_id, roadlength=segment_length, roadspeed=segment_speed,roadtime=segment_length/segment_speed)\n",
    "    return G\n",
    "def create_new_nodes(net,num_nodes):\n",
    "    # 获取所有边\n",
    "    edge_all = net.getEdges()\n",
    "    create_list=[]\n",
    "    # 随机选择一条边\n",
    "    for i in range(num_nodes):\n",
    "        edge = random.choice(edge_all)\n",
    "        lane =random.choice(edge.getLanes())\n",
    "        edge_length = edge.getLength()\n",
    "        distance=random.uniform(2, max(5,edge_length-10))\n",
    "        laneID=lane.getID()\n",
    "        shape = edge.getShape()# 获取边起止点的坐标\n",
    "        # 计算在当前线段上的位置\n",
    "        ratio = distance / edge_length\n",
    "        x = shape[0][0] + ratio * (shape[1][0] - shape[0][0])\n",
    "        y = shape[0][1] + ratio * (shape[1][1] - shape[0][1])\n",
    "        # 生成唯一的节点ID\n",
    "        node_id =( f\"Target_{i}\")\n",
    "        create_list.append([node_id, (x, y), laneID, distance])\n",
    "    return create_list\n",
    "\n",
    "def convert_net_to_digraph_simple(net):\n",
    "    # 创建一个有向图\n",
    "    G = nx.DiGraph() \n",
    "    # 遍历所有边\n",
    "    for edge in net.getEdges():\n",
    "        # 遍历边的所有车道\n",
    "        for outgoing_edge in edge.getOutgoing():\n",
    "            segment_length=edge.getLength()\n",
    "            segment_speed = edge.getSpeed()\n",
    "            from_edge_id=edge.getID()\n",
    "            to_edge_id=outgoing_edge.getID()\n",
    "            G.add_edge(from_edge_id, to_edge_id, roadlength=segment_length, roadspeed=segment_speed,roadtime=segment_length/segment_speed)\n",
    "    return G\n",
    "\n",
    "def convert_net_to_digraph(net,add_nodes):\n",
    "    # 创建一个有向图\n",
    "    G = nx.DiGraph() \n",
    "    # 遍历所有边\n",
    "    for edge in net.getEdges():\n",
    "        # 遍历边的所有车道\n",
    "        for lane_index, lane in enumerate(edge.getLanes()):\n",
    "            # 获取车道ID\n",
    "            lane_node_id = lane.getID()\n",
    "            # 遍历出边\n",
    "            for ToEdge in edge.getOutgoing():\n",
    "                # 获取连接列表\n",
    "                conn_list=edge.getConnections(ToEdge)\n",
    "                # 遍历连接\n",
    "                for ToConnection in conn_list:\n",
    "                    #获取车道ID\n",
    "                    to_lane_node_id = ToConnection.getToLane().getID()\n",
    "                     # 获取交通信号灯和连接索引\n",
    "#                     print(dir(ToConnection))\n",
    "                    tl = ToConnection.getTLSID()  # 获取交通信号灯ID\n",
    "                    linkIndex = ToConnection.getTLLinkIndex()  # 获取连接索引\n",
    "#                     print(f\"tl ID:{tl}, index ID: {linkIndex}\")\n",
    "                    # 合并交通信号灯和连接索引\n",
    "                    segment_tl = f\"{tl}_{linkIndex}\" if tl else None\n",
    "                    # 定义边属性\n",
    "                    segment_speed = edge.getSpeed()\n",
    "                    segment_length= edge.getLength()\n",
    "#                     print(to_lane_node_id)\n",
    "                    # 在有向图中添加边\n",
    "                    G.add_edge(lane_node_id, to_lane_node_id, roadlength=segment_length, roadspeed=segment_speed,roadtime=segment_length/segment_speed,trafficlight=segment_tl)\n",
    "#     print(G.nodes())\n",
    "    target_list=[]\n",
    "    for i in range(len(add_nodes)):\n",
    "        origin_node=add_nodes[i][2]\n",
    "        distance=add_nodes[i][3]\n",
    "        new_node_ID1=f\"A_{origin_node}\"\n",
    "        new_node_ID2=f\"B_{origin_node}\"\n",
    "        # 继承节点u的所有入边\n",
    "#         print(origin_node)\n",
    "        for predecessor in list(G.predecessors(origin_node)):\n",
    "#             print(predecessor)\n",
    "#             print(origin_node)\n",
    "            segment_length=G[predecessor][origin_node]['roadlength']\n",
    "            segment_speed=G[predecessor][origin_node]['roadspeed']\n",
    "            G.add_edge(predecessor, new_node_ID1, roadlength=segment_length, roadspeed=segment_speed,roadtime=segment_length/segment_speed)\n",
    "            G.remove_edge(predecessor, origin_node)\n",
    "\n",
    "        # 继承节点u的所有出边\n",
    "        for successor in list(G.successors(origin_node)):\n",
    "            segment_length=G[origin_node][successor]['roadlength']\n",
    "            segment_speed=G[origin_node][successor]['roadspeed']\n",
    "            G.add_edge(new_node_ID2, successor, roadlength=segment_length, roadspeed=segment_speed,roadtime=segment_length/segment_speed)\n",
    "            G.remove_edge(origin_node, successor)\n",
    "        # 新增边(u1, u2)\n",
    "        G.add_edge(new_node_ID1, new_node_ID2, roadlength=distance, roadspeed=segment_speed,roadtime=segment_length/segment_speed,trafficlight=None)\n",
    "        target_list.append(new_node_ID2)\n",
    "#     原节点的所有入边和出边都删除后，该节点自动删除\n",
    "#     for i in range(len(add_nodes)):\n",
    "#         origin_node=add_nodes[i][2]\n",
    "#         # 删除原节点u\n",
    "#         G.remove_node(origin_node)\n",
    "\n",
    "    return G,target_list\n",
    "def calculate_filted_path(G, source_node, target_node, length_cutoff_gain, node_cutoff_add,time_cutoff_gain):\n",
    "    minPath_L = nx.dijkstra_path(G, source_node, target_node, weight='roadlength')\n",
    "    L_minPath=nx.dijkstra_path_length(G, source_node, target_node, weight='roadlength')\n",
    "    num_node_L=len(minPath_L)\n",
    "    minPath_T = nx.dijkstra_path(G, source_node, target_node, weight='roadtime')\n",
    "    T_minPath=nx.dijkstra_path_length(G, source_node, target_node, weight='roadtime')\n",
    "    num_node_T=len(minPath_L)\n",
    "    node_cutoff=node_cutoff_add+min(num_node_L,num_node_T)\n",
    "    length_cutoff=length_cutoff_gain*L_minPath\n",
    "    time_cutoff=time_cutoff_gain*T_minPath\n",
    "    # 存储所有路径及其长度的列表\n",
    "    path_lengths = []\n",
    "    if length_cutoff_gain==1 and node_cutoff_add==0 and time_cutoff_gain==1:\n",
    "        path_all=[minPath_L,minPath_T]\n",
    "    else:    \n",
    "        path_all=nx.all_simple_paths(G, source_node, target_node, cutoff=node_cutoff)\n",
    "    # 生成所有简单路径\n",
    "    for i, path in enumerate(path_all):\n",
    "        # 计算路径长度\n",
    "        path_length = sum(G[path[i]][path[i+1]].get('roadlength', None) for i in range(len(path) - 1))\n",
    "        path_time = sum(G[path[i]][path[i+1]].get('roadtime', None)  for i in range(len(path) - 1))\n",
    "        if length_cutoff> path_length and time_cutoff> path_time:\n",
    "            # 将路径及其长度添加到列表中\n",
    "            path_lengths.append(path)\n",
    "        else:\n",
    "            continue\n",
    "    return path_lengths,minPath_L,minPath_T\n",
    "def create_graph_from_paths(paths):\n",
    "    G = nx.DiGraph()\n",
    "    for path in paths:\n",
    "        for i in range(len(path) - 1):\n",
    "            # 获取路径中的每对节点\n",
    "            u, v = path[i], path[i + 1]\n",
    "            # 为图中的每对节点添加一条边，并设置权重\n",
    "            if not G.has_edge(u, v):\n",
    "                G.add_edge(u, v)\n",
    "    return G\n",
    "def create_graph_list(G,start_node,target_nodes,node_cutoff_add,length_cutoff_gain,time_cutoff_gain,indexed_targets=None):\n",
    "#     target_nodes = list(range(start_node+1, num_nodes))\n",
    "#     target_nodes = [str(num) for num in range(43,G.number_of_nodes())]\n",
    "    if indexed_targets!=None:\n",
    "        all_target_permutations=[indexed_targets]\n",
    "#         print(1)\n",
    "    else:      \n",
    "        all_target_permutations = list(permutations(target_nodes))\n",
    "    graph_list = []\n",
    "    graph_union=nx.DiGraph()\n",
    "    possible_path_L=[]\n",
    "    possible_path_T=[]\n",
    "    for permutation_i in all_target_permutations:\n",
    "        source_node=start_node\n",
    "        graph_row=[]\n",
    "        possible_path_row_L=[]\n",
    "        possible_path_row_T=[]\n",
    "        for i in range(len(permutation_i)):\n",
    "            target_node = permutation_i[i]\n",
    "#             print(f'source node: {source_node}, target_node: {target_node}')\n",
    "            paths,minPath_L,minPath_T = calculate_filted_path(G, source_node, target_node, length_cutoff_gain, node_cutoff_add,time_cutoff_gain)\n",
    "            G_created=create_graph_from_paths(paths)\n",
    "            source_node=permutation_i[i]\n",
    "            graph_row.append(G_created)\n",
    "            graph_union=nx.compose(graph_union, G_created)\n",
    "#             print(f'Combined graph {graph_union} and created graph {G_created}')\n",
    "            if i==0:\n",
    "                possible_path_row_L=possible_path_row_L+minPath_L\n",
    "                possible_path_row_T=possible_path_row_T+minPath_T\n",
    "            else:\n",
    "                possible_path_row_L=possible_path_row_L+minPath_L[1:]\n",
    "                possible_path_row_T=possible_path_row_T+minPath_T[1:]\n",
    "        if len(all_target_permutations)==1:\n",
    "#             print('Indexed targets with 1 permutation')\n",
    "            graph_list=graph_row\n",
    "            possible_path_L=possible_path_row_L\n",
    "            possible_path_T=possible_path_row_T\n",
    "        else:\n",
    "            graph_list.append(graph_row)\n",
    "            possible_path_L.append(possible_path_row_L)\n",
    "            possible_path_T.append(possible_path_row_T)\n",
    "    return graph_list,graph_union,all_target_permutations,possible_path_L,possible_path_T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sumolib.net.readNet(\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\sourceCICT.net.xml\")\n",
    "G_simple=convert_net_to_digraph_simple(net)\n",
    "generate_num=10\n",
    "target_num=8\n",
    "rd_nodes=create_new_nodes(net,generate_num+1)\n",
    "G_original,generate_list=convert_net_to_digraph(net,rd_nodes)\n",
    "# print(G_original.nodes())\n",
    "# print(generate_list)\n",
    "DJL_database=[]\n",
    "DJT_database=[]\n",
    "start_database=[]\n",
    "target_database=[]\n",
    "set_num=20*len(generate_list)\n",
    "max_num=len(list(permutations(generate_list)))\n",
    "print(f\"set number of generation: {set_num}, max number of generation: {max_num}\")\n",
    "start_time = time.time()\n",
    "start_node_list=[]\n",
    "database_dic={}\n",
    "node_cutoff_add=0\n",
    "length_cutoff_gain=1\n",
    "time_cutoff_gain=1\n",
    "i=0\n",
    "sample_counter=0\n",
    "error_counter=0\n",
    "free_counter=0\n",
    "generate_set_simple=set()\n",
    "for additional_node in generate_list:\n",
    "    additional_node_simple=additional_node.split(\"_\")[1]\n",
    "    generate_set_simple.add(additional_node_simple)\n",
    "generate_list_simple=list(generate_set_simple)\n",
    "# generate_list_simple=['27-26', '19-26', '28-21', '36-37', '21-20', '9-17', '17-18', '33-40', '23-24', '30-37', '10-9']\n",
    "print(generate_list_simple)\n",
    "while i<min(set_num,max_num):\n",
    "# for i in range(min(set_num,max_num)):\n",
    "    data_single={}\n",
    "    start_node_simple= random.choice(generate_list_simple)\n",
    "    start_initial_counter=1\n",
    "    while start_node_simple in start_node_list and start_initial_counter<10:\n",
    "        start_node_simple= random.choice(generate_list_simple)\n",
    "        start_initial_counter=start_initial_counter+1\n",
    "    original_list = [item for item in generate_list_simple if item != start_node_simple]\n",
    "    target_list = random.sample(original_list,target_num)\n",
    "#     print(target_list)\n",
    "    indexed_targets_simple=list(random.choice(list(permutations(target_list))))\n",
    "    G_list,G_combined,_,possible_path_L,possible_path_T=create_graph_list(G_simple,start_node_simple,target_list,6,1.2,1.2,indexed_targets_simple)\n",
    "    break_flag=False\n",
    "    sample_counter=sample_counter+1\n",
    "    if sample_counter%10==1:\n",
    "        print(f\"{sample_counter}th sample\")\n",
    "    for index_i in range(len(G_list)):\n",
    "        G=G_list[index_i]\n",
    "        if len(G.nodes())==0:\n",
    "            print(\"空路径无法组成搜索图！\")\n",
    "            break_flag=True\n",
    "            break\n",
    "        try:\n",
    "            cycle = nx.find_cycle(G)\n",
    "#             print(f\"Cycle found: {cycle} of vehicle {str(vehicle_id_index)} toward {control_dic[str(vehicle_id_index)]['targets'][index]} within {control_dic[str(vehicle_id_index)]['targets']}\")\n",
    "            break_flag=True\n",
    "            error_counter=error_counter+1\n",
    "            print(\"有环图不适用！ \")\n",
    "            break\n",
    "        except nx.NetworkXNoCycle:\n",
    "            free_counter=free_counter+1\n",
    "#             print(\"无环图！ \")\n",
    "    if break_flag:\n",
    "        continue\n",
    "    data_single['Graph list']=G_list\n",
    "    data_single['Combined graph']=G_combined\n",
    "    data_single['Start']=start_node_simple\n",
    "    data_single['Targets']=target_list\n",
    "    data_single['Indexed Targets']=indexed_targets_simple\n",
    "    data_single['Possible DJL']=possible_path_L\n",
    "    data_single['Possible DJT']=possible_path_T\n",
    "    database_dic[i]=data_single\n",
    "    start_node_list.append(start_node_simple)\n",
    "    i=i+1\n",
    "end_time = time.time()      \n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"程序运行耗时: {elapsed_time:.6f} 秒, 共计采样 {sample_counter} 次，获得样本{i}例\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在生成后的数据库字典database_dic中随机初始化N辆车，各自路由选择其中的“Possible DJL”和“Possible DJT”，分别写入SUMO的路由文件（.rou.xml），用作baseline实验配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NX2SUMO_route_converted(node_path):\n",
    "    if any(isinstance(i, list) for i in node_path):\n",
    "        num_route=len(node_path)\n",
    "    else:\n",
    "        num_route=1\n",
    "    edge_matrix=[]\n",
    "#     print(num_route)\n",
    "    for i in range(num_route):\n",
    "        route=[]\n",
    "        edge_id_last=[]\n",
    "        path=node_path[i]\n",
    "        for lane_id in path:\n",
    "            # 检查是否为新增节点\n",
    "            if lane_id.startswith('A_') or lane_id.startswith('B_'):\n",
    "                # 提取最近边ID\n",
    "                edge_id = lane_id.split('_')[1]\n",
    "                if edge_id==edge_id_last:\n",
    "                    continue\n",
    "            else:\n",
    "                # 提取边ID\n",
    "                edge_id = lane_id.rsplit('_', 1)[0]\n",
    "            route.append(edge_id)\n",
    "            edge_id_last=edge_id\n",
    "        edge_matrix.append(route)        \n",
    "    return edge_matrix\n",
    "def write_routes_to_xml(net, edge_matrix, output_path, num_vehicles=None, num_vehicle_types=3):\n",
    "    \"\"\"\n",
    "    将生成的edge_matrix写入.rou.xml文件中，并生成N辆车辆，每辆车的类型随机化。\n",
    "    \n",
    "    参数:\n",
    "    net (sumolib.net.Net): 通过sumolib读取的路网对象\n",
    "    edge_matrix (list of lists): 二维列表，每个元素是一个edge_list\n",
    "    output_path (str): 输出文件的路径\n",
    "    num_vehicles (int): 生成的车辆数量，如果为None，则随机生成\n",
    "    num_vehicle_types (int): 预定义的车辆类型数量\n",
    "    \"\"\"\n",
    "    # 如果num_vehicles为None，则随机生成一个车辆数量\n",
    "#     print(edge_matrix[:][0])\n",
    "    if num_vehicles is None:\n",
    "        num_vehicles = random.randint(1, 10)  # 生成1到10之间的随机整数\n",
    "    \n",
    "    # 生成预定义的车辆类型\n",
    "    vehicle_types = []\n",
    "    # 定义可能的guiShape值\n",
    "    gui_shapes = [\"passenger\", \"truck\", \"evehicle\"]\n",
    "    # 定义可能的laneChangeModel值\n",
    "    lane_change_models = [\"LC2013\", \"SL2015\"]\n",
    "    # 定义可能的carFollowModel值\n",
    "    car_follow_models = [\"PWagner2009\", \"IDM\", \"Krauss\", \"SmartSK\", \"W99\", \"CACC\"]\n",
    "    \n",
    "    for i in range(num_vehicle_types):\n",
    "        gain=random.uniform(0.5, 1.5)\n",
    "        select_guishape=random.choice(gui_shapes)\n",
    "        select_lanechange=random.choice(lane_change_models)\n",
    "        select_carfollow=random.choice(car_follow_models)\n",
    "#         vehicle_types.append(f\"\"\"\n",
    "#     <vType id=\"type{i+1}\" accel=\"{gain}\" decel=\"{gain * 2}\" sigma=\"{random.uniform(0.1, 0.9)}\" tau=\"{2* gain**0.5}\" length=\"{3 / gain}\" maxSpeed=\"{30 + gain * 20}\" guiShape=\"{select_guishape}\" laneChangeModel=\"{select_lanechange}\" carFollowModel=\"{select_carfollow}\"/>\n",
    "# \"\"\")\n",
    "        vehicle_types.append(f\"\"\"\n",
    "    <vType id=\"type{i+1}\" accel=\"{gain}\" decel=\"{gain * 2}\" sigma=\"{random.uniform(0.1, 0.9)}\" tau=\"{2* gain**0.5}\" length=\"{3 / gain}\" maxSpeed=\"{30 + gain * 20}\" guiShape=\"{select_guishape}\" laneChangeModel=\"LC2013\" />\n",
    "\"\"\")\n",
    "\n",
    "        \n",
    "    \n",
    "    # 生成路线文件内容\n",
    "    route_xml = \"\"\"\n",
    "<routes>\n",
    "\"\"\" + ''.join(vehicle_types) + \"\"\"\n",
    "\"\"\"\n",
    "    \n",
    "    # 检查每个edge_list中的边是否存在，并且连接是否有效\n",
    "    for edge_list in edge_matrix:\n",
    "        for i in range(len(edge_list) - 1):\n",
    "            current_edge = edge_list[i]\n",
    "            next_edge = edge_list[i + 1]\n",
    "            \n",
    "            # 检查当前边是否存在\n",
    "            if not net.hasEdge(current_edge):\n",
    "                raise ValueError(f\"边 {current_edge} 不在路网中\")\n",
    "            \n",
    "            # 获取当前边和下一条边的对象\n",
    "            current_edge_obj = net.getEdge(current_edge)\n",
    "            next_edge_obj = net.getEdge(next_edge)\n",
    "            # 检查连接是否存在\n",
    "            outgoing_edges = current_edge_obj.getOutgoing()\n",
    "            if next_edge_obj not in outgoing_edges:\n",
    "                raise ValueError(f\"边 {current_edge} 和边 {next_edge} 之间没有有效的连接\")\n",
    "#     print(edge_matrix[:][0])\n",
    "    selected_route_list=[]\n",
    "    selected_vehicle_list=[]\n",
    "    for i in range(num_vehicles):\n",
    "        selected_route_index=random.choice(range(len(edge_matrix)))\n",
    "        selected_route_list.append(selected_route_index)\n",
    "        selected_vehicle_index=random.choice(range(len(vehicle_types)))\n",
    "        selected_vehicle_list.append(selected_vehicle_index)\n",
    "        edge_list = edge_matrix[selected_route_index]  # 随机选择一个edge_list\n",
    "        vehicle_type = vehicle_types[selected_vehicle_index]  # 随机选择一个车辆类型\n",
    "        route_xml += f\"\"\"\n",
    "    <vehicle id=\"{i}\" type=\"{vehicle_type.split()[1].split('=')[1].strip('\"')}\" depart=\"0\" color=\"1,0,0\">\n",
    "      <route edges=\"{' '.join(edge_list)}\"/>\n",
    "    </vehicle>\n",
    "\"\"\"\n",
    "    route_xml += \"\"\"\n",
    "</routes>\n",
    "\"\"\"\n",
    "    # 将内容写入文件\n",
    "    with open(output_path, \"w\") as file:\n",
    "        file.write(route_xml)\n",
    "    print(f\"路线文件已生成: {output_path}\")\n",
    "    return vehicle_types,edge_matrix,selected_route_list,selected_vehicle_list\n",
    "\n",
    "def write_routes_to_xml_recurrent(output_path,vehicle_types,edge_matrix,selected_route_index,selected_vehicle_index):\n",
    "    route_xml = \"\"\"\n",
    "<routes>\n",
    "\"\"\" + ''.join(vehicle_types) + \"\"\"\n",
    "\"\"\"\n",
    "    for j in range(len(selected_route_index)):\n",
    "        i=selected_route_index[j]\n",
    "        k=selected_vehicle_index[j]\n",
    "        edge_list = edge_matrix[i]  # 随机选择一个edge_list\n",
    "        vehicle_type = vehicle_types[k]  # 随机选择一个车辆类型\n",
    "        route_xml += f\"\"\"\n",
    "    <vehicle id=\"{j}\" type=\"{vehicle_type.split()[1].split('=')[1].strip('\"')}\" depart=\"0\" color=\"1,0,0\">\n",
    "      <route edges=\"{' '.join(edge_list)}\"/>\n",
    "    </vehicle>\n",
    "\"\"\"\n",
    "    route_xml += \"\"\"\n",
    "</routes>\n",
    "\"\"\"\n",
    "    # 将内容写入文件\n",
    "    with open(output_path, \"w\") as file:\n",
    "        file.write(route_xml)\n",
    "    print(f\"路线文件已生成: {output_path}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sumolib.net.readNet(\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\sourceCICT.net.xml\")     \n",
    "vehicle_num=300\n",
    "vehicle_type_num=10\n",
    "test_paths_DJL=[]\n",
    "test_paths_DJT=[]\n",
    "test_paths_mix=[]\n",
    "for i in range(len(database_dic)):\n",
    "    test_paths_DJL.append(database_dic[i]['Possible DJL'])\n",
    "    test_paths_DJT.append(database_dic[i]['Possible DJT'])\n",
    "    test_paths_mix.append( random.choice( [ database_dic[i]['Possible DJL'],database_dic[i]['Possible DJT'] ]) )\n",
    "\n",
    "output_path_DJL = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\route_DJL.rou.xml\"       \n",
    "edge_matrix_DJL=NX2SUMO_route_converted(test_paths_DJL)\n",
    "vehicle_types,_,selected_route_list,selected_vehicle_list=write_routes_to_xml(net, edge_matrix_DJL, output_path_DJL, vehicle_num, vehicle_type_num)\n",
    "output_path_DJT = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\route_DJT.rou.xml\"       \n",
    "edge_matrix_DJT=NX2SUMO_route_converted(test_paths_DJT)\n",
    "write_routes_to_xml_recurrent(output_path_DJT, vehicle_types, edge_matrix_DJT, selected_route_list,selected_vehicle_list)\n",
    "output_path_mix = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\route_mix.rou.xml\"       \n",
    "edge_matrix_mix=NX2SUMO_route_converted(test_paths_mix)\n",
    "write_routes_to_xml_recurrent(output_path_mix, vehicle_types, edge_matrix_mix, selected_route_list,selected_vehicle_list)\n",
    "database_baseline={'Possible DJLs list':edge_matrix_DJL,'Possible DJLs list':edge_matrix_DJL,'Possible mixed paths':edge_matrix_mix,'Possible vehicle types list':vehicle_types,'Routes index list': selected_route_list,'Vehicles index list': selected_vehicle_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到：D:\\\\SUMO\\\\work\\\\rebuild2\\\\basic_database.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_file_path = r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\basic_database.pkl\"  # 替换为你想要保存的文件名\n",
    "with open(output_file_path, 'wb') as file:\n",
    "    pickle.dump((database_dic,database_baseline), file)\n",
    "\n",
    "print(f\"数据已保存到：{output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\\SUMO\\\\work\\\\rebuild2\\\\basic_database.pkl数据已加载\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_file_path = r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\basic_database.pkl\"  # 替换为你想要保存的文件名\n",
    "# 使用pickle从文件加载列表\n",
    "with open(output_file_path, 'rb') as file:\n",
    "    database_dic,database_baseline = pickle.load(file)\n",
    "    \n",
    "print(f\"{output_file_path}数据已加载\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于SCIP的排队长度最小车道规划"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_change_cost(current_lane,target_lane,obstacle_position,obstacle_target):\n",
    "    basic_change_cost=np.abs(current_lane-target_lane)\n",
    "    cross_collision=0\n",
    "    conflict_collision=0\n",
    "    for i in range(len(obstacle_position)):\n",
    "        if obstacle_position[i] == target_lane and obstacle_target[i] == current_lane:\n",
    "            cross_collision += 1\n",
    "        if obstacle_position[i] == target_lane and obstacle_target[i] == target_lane:\n",
    "            conflict_collision += 1\n",
    "    collision_cost=cross_collision+conflict_collision\n",
    "    total_cost=basic_change_cost+collision_cost\n",
    "#     print(f\"basic cost: {basic_change_cost}, collision cost: {collision_cost}, total cost: {total_cost}\")\n",
    "    return total_cost\n",
    "def lane_assignment_optimization(assign_position,obstacle_position,obstacle_target,available_target,total_lane):\n",
    "    cost_matrix=[]\n",
    "    decision_matrix=[]\n",
    "    model = Model(\"Lane Assignment\")\n",
    "    for i in range(len(available_target)):\n",
    "        cost_row=[]\n",
    "        decision_row=[]\n",
    "        current_lane=assign_position[i]\n",
    "#         print(available_target[i])\n",
    "        for j in available_target[i]:\n",
    "#             print(f\"current lane in available horizon: {j}\")\n",
    "            cost_current=lane_change_cost(current_lane,j,obstacle_position,obstacle_target)\n",
    "            cost_row.append(cost_current)\n",
    "            decision_row.append( model.addVar(vtype=\"B\", name=f\"x({i},{j})\"))\n",
    "        decision_matrix.append(decision_row)\n",
    "        cost_matrix.append(cost_row)\n",
    "#     print(f\"decision dimension: {len(decision_matrix)}\")\n",
    "#     print(f\"cost matrix: {cost_matrix}\")\n",
    "    z= model.addVar(vtype=\"M\", name=f\"platoon_length\")\n",
    "    for i in range(len(available_target)):  # 每个车辆恰好被分配到一个车道\n",
    "        model.addCons(sum(decision_matrix[i][j] for j in range(len(available_target[i]))) == 1)  \n",
    "    for i in total_lane: # 隐变量大于等于每个车道预期的编队总长度\n",
    "        constant_platoon=obstacle_target.count(i)\n",
    "        model.addCons(z>=constant_platoon+sum(decision_matrix[j][available_target[j].index(i)] for j in range(len(available_target)) if i in available_target[j])) \n",
    "    model.setObjective(2*z+0.5*sum(cost_matrix[i][j] * decision_matrix[i][j] for i in range(len(available_target)) for j in range(len(available_target[i]))), \"minimize\" )  # 设置目标函数：最小化队列长度+换道成本 \n",
    "    model.optimize()  # 求解优化模型\n",
    "    assign_target=[]\n",
    "    for i in range(len(available_target)):\n",
    "        for j in range(len(available_target[i])):\n",
    "            if model.getVal(decision_matrix[i][j]) > 0.5:\n",
    "                assign_target.append(available_target[i][j])\n",
    "    return assign_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 离线字典生成（不需要SUMO和TraCI）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_step_decision_list_generation(G):\n",
    "    action_dict={}\n",
    "    action_detail_dict={}\n",
    "    for current_node in G.nodes():\n",
    "        action_list=[]\n",
    "        current_action_list=[]\n",
    "        if len(list(G.successors(current_node)))==0:\n",
    "            action_list.append([None,None])\n",
    "            action_dict[current_node]=action_list\n",
    "            current_action_list.append(None)\n",
    "            action_detail_dict[current_node]=current_action_list\n",
    "            continue\n",
    "        for next_node in G.successors(current_node):\n",
    "            current_action_list.append(next_node)\n",
    "            if len(list(G.successors(next_node)))==0:\n",
    "                action_list.append([next_node,None])\n",
    "                break\n",
    "            for next_next_node in G.successors(next_node):\n",
    "                action_list.append([next_node,next_next_node])\n",
    "        action_detail_dict[current_node]=current_action_list\n",
    "        action_dict[current_node]=action_list\n",
    "    return action_dict,action_detail_dict\n",
    "\n",
    "def control_dictionary_initialize(G_total_dic,targets_dic,vehicle_ids):\n",
    "    control_dict={}\n",
    "    for vehicle_i in vehicle_ids:\n",
    "        current_dict={}\n",
    "        indexed_target=targets_dic[vehicle_i]\n",
    "        action_list_single_S2T=[]\n",
    "        action_detail_single_S2T=[]\n",
    "        for index in range(len(indexed_target)):\n",
    "            G=G_total_dic[vehicle_i][index]\n",
    "            action_dict,action_detail_dict=two_step_decision_list_generation(G)\n",
    "            action_list_single_S2T.append(action_dict)\n",
    "            action_detail_single_S2T.append(action_detail_dict)\n",
    "        current_dict['uk']=None\n",
    "        current_dict['Tlane']=None\n",
    "        current_dict['detailed action dictionary']=action_detail_single_S2T\n",
    "        current_dict['action list']=action_list_single_S2T\n",
    "        current_dict['targets']=indexed_target\n",
    "        current_dict['Route']=[]\n",
    "        current_dict['recorded route']=[]\n",
    "        current_dict['stage']=0\n",
    "        control_dict[vehicle_i]=current_dict\n",
    "    return control_dict\n",
    "\n",
    "def lane_set_generation(net):\n",
    "    all_edges=net.getEdges()\n",
    "    search_dic={} # 从edge1出发至edge2，可选择出发的edge1车道序号\n",
    "    possible_dic={} # 从edge1出发至edge2，从edge1的车道i出发，可能到达的edge2车道序号\n",
    "    for edge in all_edges:\n",
    "        source_edge_id=edge.getID()\n",
    "        all_outgoing=edge.getOutgoing()\n",
    "        search_dic[source_edge_id]={}\n",
    "        possible_dic[source_edge_id]={}\n",
    "        for ic_edge in all_outgoing:\n",
    "            target_edge_id=ic_edge.getID()\n",
    "            connections=all_outgoing[ic_edge]\n",
    "            constrains_list=set()\n",
    "            possible_dic[source_edge_id][target_edge_id]={}\n",
    "            for connection_i in connections:\n",
    "                from_lane=connection_i.getFromLane().getID()\n",
    "                to_lane=connection_i.getToLane().getID()\n",
    "                fromlane_index=int(from_lane.split('_')[-1])\n",
    "                tolane_index=int(to_lane.split('_')[-1])\n",
    "                constrains_list.add(fromlane_index)\n",
    "                possible_dic[source_edge_id][target_edge_id][fromlane_index]=set()\n",
    "            for connection_i in connections:\n",
    "                from_lane=connection_i.getFromLane().getID()\n",
    "                to_lane=connection_i.getToLane().getID()\n",
    "                fromlane_index=int(from_lane.split('_')[-1])\n",
    "                tolane_index=int(to_lane.split('_')[-1])\n",
    "                possible_dic[source_edge_id][target_edge_id][fromlane_index].add(tolane_index)\n",
    "            search_dic[source_edge_id][target_edge_id]=list(constrains_list)   \n",
    "    edge_search_dic={'Possible from lanes':search_dic,'Possible to lanes':possible_dic}\n",
    "    return edge_search_dic\n",
    "\n",
    "\n",
    "seleted_indexes_list=database_baseline['Routes index list']\n",
    "# print(seleted_indexes_list)\n",
    "G_total_dict={}\n",
    "targets_dict={}\n",
    "vehicle_ids=[]\n",
    "for iteration_index in range(len(seleted_indexes_list)):\n",
    "    vehicle_index=seleted_indexes_list[iteration_index]\n",
    "    vehicle_id=str(iteration_index)\n",
    "    current_data_index=seleted_indexes_list[vehicle_index]\n",
    "    G_list=database_dic[vehicle_index]['Graph list']\n",
    "    G_total_dict[vehicle_id]=G_list\n",
    "    indexed_target_single=database_dic[vehicle_index]['Indexed Targets']\n",
    "    targets_dict[vehicle_id]=indexed_target_single\n",
    "    vehicle_ids.append(vehicle_id)\n",
    "net = sumolib.net.readNet(\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\sourceCICT.net.xml\")\n",
    "control_dict={}\n",
    "control_dict=control_dictionary_initialize(G_total_dict,targets_dict,vehicle_ids)\n",
    "edge_search_dic=lane_set_generation(net)\n",
    "# print(control_dict['49']['uk'])\n",
    "# print(control_dict['49']['Route'])\n",
    "# print(control_dict['49']['recorded route'])\n",
    "# print(control_dict['49']['targets'])\n",
    "# print(control_dict['49']['stage'])\n",
    "# print(control_dict['49']['action list'][control_dict['49']['stage']])\n",
    "# print(control_dict['49']['action list'][control_dict['49']['stage']+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 离线字典生成（需要SUMO和TraCI，但无需实时重生成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lists(A, B):\n",
    "    # 创建字典，以 A 中的元素为键，B 中的元素为值\n",
    "    mapping = {}\n",
    "    for a, b in zip(A, B):\n",
    "        if a not in mapping:\n",
    "            mapping[a] = []\n",
    "        mapping[a].append(b)\n",
    "\n",
    "    # 创建字典，以 B 中的元素为键，A 中的元素为值\n",
    "    reverse_mapping = {}\n",
    "    for a, b in zip(A, B):\n",
    "        if b not in reverse_mapping:\n",
    "            reverse_mapping[b] = []\n",
    "        reverse_mapping[b].append(a)\n",
    "    return mapping, reverse_mapping\n",
    "\n",
    "def trafficlight_dic_generation(TL_id):\n",
    "    total_phases=traci.trafficlight.getCompleteRedYellowGreenDefinition(TL_id)[0].getPhases()\n",
    "#     total_connections=net.getNode(TL_id).getConnections()\n",
    "    controlled_links = traci.trafficlight.getControlledLinks(TL_id)\n",
    "    crossing_duration=[]\n",
    "    crossing_edges=[]\n",
    "    crossing_lanes=[]\n",
    "    moving_to_lanes=[]\n",
    "    moving_to_edges=[]\n",
    "    for i, phase_now in enumerate(total_phases):\n",
    "        whole_states=phase_now.state\n",
    "#         print(f'States number: {len(whole_states)}, links number: {len(controlled_links)}')\n",
    "        duration_now=phase_now.duration\n",
    "        target_edges=set()\n",
    "        allowed_edges=set()\n",
    "        allowed_lanes=[]\n",
    "        target_lanes=[]\n",
    "        for j,state_now in enumerate(whole_states):\n",
    "            if state_now in ['g','G']:\n",
    "                link_now=controlled_links[j]\n",
    "                for item in link_now:\n",
    "                    From_lane, To_lane, _ = item\n",
    "                FromEdge_id=From_lane.split(\"_\")[0]\n",
    "                ToEdge_id=To_lane.split(\"_\")[0]\n",
    "            else:\n",
    "                continue\n",
    "            allowed_edges.add(FromEdge_id)\n",
    "            target_edges.add(ToEdge_id)\n",
    "            allowed_lanes.append(From_lane)\n",
    "            target_lanes.append(To_lane)\n",
    "        mapping_from,mapping_to=process_lists(allowed_lanes, target_lanes)\n",
    "        crossing_duration.append(duration_now)\n",
    "        crossing_edges.append(list(allowed_edges))\n",
    "        crossing_lanes.append(mapping_from)\n",
    "        moving_to_lanes.append(mapping_to)\n",
    "        moving_to_edges.append(list(target_edges))\n",
    "        cycle_time=sum(crossing_duration)\n",
    "    return TL_id,{'Cycle time':cycle_time,'Phase number': len(total_phases),'Duration list':crossing_duration,'FromEdge list':crossing_edges,'ToEdge list':moving_to_edges,'FromLane list':crossing_lanes,'ToLane list':moving_to_lanes}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 车道分布预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_based_graph_generation(edge_id,net):\n",
    "    G_current=nx.DiGraph()\n",
    "    if edge_id=='10-11':\n",
    "        lane_set=[0,1,2]\n",
    "        vehicle_ids = traci.edge.getLastStepVehicleIDs(edge_id)+traci.edge.getLastStepVehicleIDs(':10_8')\n",
    "    elif edge_id=='11-10':\n",
    "        lane_set=[0,1,2]\n",
    "        vehicle_ids = traci.edge.getLastStepVehicleIDs(edge_id)+traci.edge.getLastStepVehicleIDs(':11_0')\n",
    "    else:\n",
    "        edge=net.getEdge(edge_id)\n",
    "        lanes=edge.getLanes()\n",
    "        lane_set=[]\n",
    "        for i in lanes:\n",
    "            lane_id=i.getID()\n",
    "            index=int(lane_id.split(\"_\")[-1])\n",
    "            lane_set.append(index)\n",
    "        vehicle_ids = traci.edge.getLastStepVehicleIDs(edge_id)\n",
    "    \n",
    "    for vehicle in vehicle_ids:\n",
    "        lane_id=traci.vehicle.getLaneID(vehicle)\n",
    "        if edge_id=='10-11' or edge_id=='11-10':\n",
    "            reading_lane_index=int(traci.vehicle.getLaneIndex(vehicle))\n",
    "            if reading_lane_index==0:\n",
    "                lane_index=0\n",
    "            elif reading_lane_index==1 or reading_lane_index==2:\n",
    "                lane_index=1\n",
    "            else:\n",
    "                lane_index=2\n",
    "        else:\n",
    "            lane_index=int(lane_id.split(\"_\")[-1])\n",
    "        s_total=traci.lane.getLength(lane_id)\n",
    "        s_current=traci.vehicle.getLanePosition(vehicle)\n",
    "        velocity_current=traci.vehicle.getSpeed(vehicle)\n",
    "        G_current.add_node(vehicle,Clane=lane_index,speed=velocity_current,position=s_total-s_current)\n",
    "#     G_current=target_lane_initialize(G_current,lane_set)\n",
    "    final_nodes_list=[]\n",
    "    for lane_index in list(sorted(lane_set)):    \n",
    "        vehicle_in_lane = sorted([node for node, attrs in G_current.nodes(data=True) if attrs.get('Clane') == lane_index],key=lambda node: G_current.nodes[node]['position'])\n",
    "        for i in range(len(vehicle_in_lane) - 1):\n",
    "            source = vehicle_in_lane[i]\n",
    "            target = vehicle_in_lane[i + 1]\n",
    "            G_current.add_edge(source, target,distance=G_current.nodes[target]['position']-G_current.nodes[source]['position'] )\n",
    "        if len(vehicle_in_lane)==1:\n",
    "            final_nodes_list.append(vehicle_in_lane[0])\n",
    "        elif len(vehicle_in_lane)==0:\n",
    "            final_nodes_list.append(None)\n",
    "        else:\n",
    "            final_nodes_list.append(vehicle_in_lane[i + 1])\n",
    "                \n",
    "    return G_current,lane_set,final_nodes_list\n",
    "            \n",
    "\n",
    "def group_nodes_by_position(G, judgement_name,target_name,interval=10,down_index=False):\n",
    "    \"\"\"\n",
    "    将图G中的节点按照position属性分组，每组的position值范围相差指定的间隔（默认为10）。\n",
    "    返回值是一个二维列表，每个子列表包含一个区间内的节点。\n",
    "\n",
    "    参数:\n",
    "        G (networkx.Graph): 输入的图，节点必须有position属性。\n",
    "        interval (int): 每个分组的区间范围，默认为10。\n",
    "\n",
    "    返回:\n",
    "        list: 二维列表，每个子列表包含一个区间内的节点。\n",
    "    \"\"\"\n",
    "    # 提取所有节点的position属性\n",
    "    positions = [data[judgement_name] for _, data in G.nodes(data=True)]\n",
    "\n",
    "    # 找到position的最大值和最小值\n",
    "    min_position = min(positions)\n",
    "    max_position = max(positions)\n",
    "\n",
    "    # 初始化二维列表\n",
    "    grouped_nodes = []\n",
    "    grouped_target=[]\n",
    "\n",
    "    # 遍历所有节点，计算其对应的区间并分配到分组\n",
    "    for node, data in G.nodes(data=True):\n",
    "        position = data[judgement_name]\n",
    "        # 计算当前节点所属的区间起点\n",
    "        start = (position // interval) * interval\n",
    "        # 确保区间起点在合法范围内\n",
    "        start = max(min_position, min(start, max_position))\n",
    "        # 构造区间索引\n",
    "        index = int((start - min_position) // interval)\n",
    "        # 如果索引超出当前列表范围，动态扩展列表\n",
    "        while len(grouped_nodes) <= index:\n",
    "            grouped_nodes.append([])\n",
    "            grouped_target.append([])\n",
    "        # 将节点添加到对应的区间\n",
    "        grouped_nodes[index].append(node)\n",
    "        grouped_target[index].append(G.nodes[node][target_name])\n",
    "    if down_index:\n",
    "        grouped_nodes.reverse()\n",
    "        grouped_target.reverse()\n",
    "\n",
    "    return grouped_nodes,grouped_target\n",
    "    \n",
    "\n",
    "def target_lane_initialize(G,lane_set):\n",
    "    if len(G.nodes())==0:\n",
    "        return G\n",
    "    G_current=G.copy()\n",
    "# 考虑车道分配优化问题的目标车道预测\n",
    "    grouped_nodes,grouped_targets=group_nodes_by_position(G_current, 'position','Clane', 10)\n",
    "    obstacle_position=[]\n",
    "    obstacle_target=[]\n",
    "    for i in range(len(grouped_nodes)):\n",
    "        assign_position=grouped_targets[i]\n",
    "        if isinstance(lane_set, list):\n",
    "            lane_list=lane_set\n",
    "        else:\n",
    "            lane_list=list(lane_set)\n",
    "        available_target = [lane_list.copy() for _ in range(len(assign_position))]\n",
    "#         print(available_target)\n",
    "        assigned_lane=lane_assignment_optimization(assign_position,obstacle_position,obstacle_target,available_target,available_target)\n",
    "#         print(f\"assigned lane: {assigned_lane}, based on obstacles: {obstacle_position} to {obstacle_target}, begin with {assign_position}\")\n",
    "        obstacle_position=obstacle_position+assign_position\n",
    "        obstacle_target=obstacle_target+assigned_lane\n",
    "        for j in range(len(grouped_nodes[i])):\n",
    "            node_id=grouped_nodes[i][j]\n",
    "            mean = assigned_lane[j]\n",
    "            std_dev = 1\n",
    "            new_lane_index = np.random.normal(loc=mean, scale=std_dev)\n",
    "            # 确保新的车道编号在有效范围内 [0, 1, 2]\n",
    "            new_lane_index = np.clip(new_lane_index, min(lane_set), max(lane_set)).astype(int)\n",
    "            G_current.nodes[node_id]['Tlane'] = new_lane_index\n",
    "    return G_current\n",
    "\n",
    "\n",
    "\n",
    "def holding_time_axis(TL_id,DealedTL_dic,T_total):\n",
    "#     print(f\"traffic light {TL_id} predicting begin--from 'def holding_time_axis'\")\n",
    "    current_phase=traci.trafficlight.getPhase(TL_id)\n",
    "    abs_next_switching_time=traci.trafficlight.getNextSwitch(TL_id)\n",
    "    current_time = traci.simulation.getTime()\n",
    "    next_switching_time=abs_next_switching_time-current_time\n",
    "#     print(f\"time of next switching:{next_switching_time} in {TL_id}--from 'def holding_time_axis'\")\n",
    "    phase_num=DealedTL_dic[TL_id]['Phase number']\n",
    "    duration_list=DealedTL_dic[TL_id]['Duration list']\n",
    "    cycle_time=sum(duration_list)\n",
    "    starting_time=[0]\n",
    "    ending_time=[next_switching_time]\n",
    "    holding_phase=[current_phase]\n",
    "    predict_phase=current_phase\n",
    "    predict_start=0\n",
    "    predict_end=T_total\n",
    "    predict_time=0\n",
    "    while predict_time<=T_total:\n",
    "#         print(f'current phase: {holding_phase}')\n",
    "        predict_phase=holding_phase[-1]+1\n",
    "        if predict_phase>=phase_num:\n",
    "            predict_phase=predict_phase-phase_num\n",
    "        predict_start=ending_time[-1]\n",
    "        predict_end=ending_time[-1]+duration_list[predict_phase]\n",
    "        holding_phase.append(predict_phase)\n",
    "        starting_time.append(predict_start)\n",
    "        ending_time.append(predict_end)\n",
    "        predict_time=predict_end\n",
    "    ending_time[-1]=T_total\n",
    "#     print(f\"traffic light {TL_id} predicting finish--from 'def holding_time_axis'\")\n",
    "    return TL_id,{'Holding phase':holding_phase,'Starting point':starting_time,'Ending point':ending_time}\n",
    "    \n",
    "def GNN_prediction(G,T_max=10000,v_ref=15):\n",
    "    nodes_with_A = [(node, G.nodes[node]['position']) for node in G.nodes if 'position' in G.nodes[node]]\n",
    "    # 根据属性 A 对节点进行排序（从小到大）\n",
    "    num_Tlane={}\n",
    "    num_Clane={}\n",
    "    node_index_Tlane={}\n",
    "    node_index_Clane={}\n",
    "    Clanes_set=set()\n",
    "    Tlanes_set=set()\n",
    "    sorted_nodes = sorted(nodes_with_A, key=lambda x: x[1])\n",
    "    sorted_node_ids = [node[0] for node in sorted_nodes]\n",
    "    L_traveling=G.nodes[sorted_node_ids[-1]]['position']\n",
    "    k_distance=0.02\n",
    "    k_velocity=0.5\n",
    "    k_theta=1\n",
    "    k_lateral=0.1\n",
    "    d_ref=2\n",
    "    d_timeheadway=0.2\n",
    "    T_step=0.1\n",
    "    T_lanechange=5\n",
    "    lane_width=3\n",
    "    theta_steer=0.7\n",
    "    a_max=3\n",
    "    omega_max=0.5\n",
    "    state_vehicle_all={}\n",
    "    if T_max<1:\n",
    "        print(f\"For graph {G.nodes()}, the set prediction horizon {T_max} is too short——from 'def GNN_prediction'\")\n",
    "    for timestamp in range(0,T_max):\n",
    "        crossing_flag_set=set()\n",
    "        for node in sorted_node_ids:\n",
    "            if node not in state_vehicle_all:\n",
    "                state_vehicle_all[node]=[]\n",
    "                if G.nodes[node]['Clane'] not in Clanes_set:\n",
    "                    Clanes_set.add(G.nodes[node]['Clane'])\n",
    "                    num_Clane[G.nodes[node]['Clane']]=1\n",
    "                    node_index_Clane[G.nodes[node]['Clane']]=[]\n",
    "                    node_index_Clane[G.nodes[node]['Clane']].append(node)\n",
    "                else:\n",
    "                    num_Clane[G.nodes[node]['Clane']]=1+num_Clane[G.nodes[node]['Clane']]\n",
    "                    node_index_Clane[G.nodes[node]['Clane']].append(node)\n",
    "                if G.nodes[node]['Tlane'] not in Tlanes_set:\n",
    "                    Tlanes_set.add(G.nodes[node]['Tlane'])\n",
    "                    num_Tlane[G.nodes[node]['Tlane']]=1\n",
    "                    node_index_Tlane[G.nodes[node]['Tlane']]=[]\n",
    "                    node_index_Tlane[G.nodes[node]['Tlane']].append(node)\n",
    "                else:\n",
    "                    num_Tlane[G.nodes[node]['Tlane']]=1+num_Tlane[G.nodes[node]['Tlane']]\n",
    "                    node_index_Tlane[G.nodes[node]['Tlane']].append(node)\n",
    "            if timestamp==0:\n",
    "                s_current=-G.nodes[node]['position']\n",
    "                t_current=0\n",
    "                theta_current=0\n",
    "                v_current=G.nodes[node]['speed']\n",
    "            else:\n",
    "                s_current=state_vehicle_all[node][timestamp-1][0]\n",
    "                t_current=state_vehicle_all[node][timestamp-1][1]\n",
    "                theta_current=state_vehicle_all[node][timestamp-1][2]\n",
    "                v_current=state_vehicle_all[node][timestamp-1][3]\n",
    "            # 排队加速\n",
    "            index_current_Clane=node_index_Clane[G.nodes[node]['Clane']].index(node)\n",
    "            index_current_Tlane=node_index_Tlane[G.nodes[node]['Tlane']].index(node)\n",
    "            \n",
    "            if index_current_Clane==0 and index_current_Tlane==0:\n",
    "                a_k=k_velocity*(v_ref-v_current)\n",
    "            elif index_current_Clane==0:\n",
    "                prenode_Tlane=node_index_Tlane[G.nodes[node]['Tlane']][index_current_Tlane-1]\n",
    "                vpre_Tlane=state_vehicle_all[prenode_Tlane][timestamp-1][3]\n",
    "                dpre_Tlane=state_vehicle_all[prenode_Tlane][timestamp-1][0]-s_current\n",
    "                a_k_Clane=k_velocity*(v_ref-v_current)\n",
    "                a_k_Tlane=k_velocity*(vpre_Tlane-v_current)+k_distance*(dpre_Tlane-d_ref-d_timeheadway*v_current)\n",
    "                a_k=0.5*a_k_Clane+0.5*a_k_Tlane\n",
    "            elif index_current_Tlane==0:\n",
    "                prenode_Clane=node_index_Clane[G.nodes[node]['Clane']][index_current_Clane-1]\n",
    "                vpre_Clane=state_vehicle_all[prenode_Clane][timestamp-1][3]\n",
    "                dpre_Clane=state_vehicle_all[prenode_Clane][timestamp-1][0]-s_current\n",
    "                a_k_Tlane=k_velocity*(v_ref-v_current)\n",
    "                a_k_Clane=k_velocity*(vpre_Clane-v_current)+k_distance*(dpre_Clane-d_ref-d_timeheadway*v_current)\n",
    "                a_k=0.5*a_k_Clane+0.5*a_k_Tlane\n",
    "            else:\n",
    "                prenode_Clane=node_index_Clane[G.nodes[node]['Clane']][index_current_Clane-1]\n",
    "                vpre_Clane=state_vehicle_all[prenode_Clane][timestamp-1][3]\n",
    "                dpre_Clane=state_vehicle_all[prenode_Clane][timestamp-1][0]-s_current\n",
    "                prenode_Tlane=node_index_Tlane[G.nodes[node]['Tlane']][index_current_Tlane-1]\n",
    "                vpre_Tlane=state_vehicle_all[prenode_Tlane][timestamp-1][3]\n",
    "                dpre_Tlane=state_vehicle_all[prenode_Tlane][timestamp-1][0]-s_current\n",
    "                a_k_Clane=k_velocity*(vpre_Clane-v_current)+k_distance*(dpre_Clane-d_ref-d_timeheadway*v_current)\n",
    "                a_k_Tlane=k_velocity*(vpre_Tlane-v_current)+k_distance*(dpre_Tlane-d_ref-d_timeheadway*v_current)\n",
    "                a_k=0.5*a_k_Clane+0.5*a_k_Tlane\n",
    "            # 换道规划\n",
    "            lanechange_direction=np.sign(G.nodes[node]['Tlane']-G.nodes[node]['Clane'])\n",
    "            if lanechange_direction==0:\n",
    "                omega_k=0\n",
    "            else:\n",
    "                if abs(t_current)<abs(G.nodes[node]['Tlane']-G.nodes[node]['Clane'])*lane_width/2:\n",
    "                    omega_k=k_theta*(theta_steer-theta_current)*lanechange_direction\n",
    "                else:\n",
    "                    omega_k=k_theta*(0-theta_current)+k_lateral*((G.nodes[node]['Tlane']-G.nodes[node]['Clane'])*lane_width-t_current)\n",
    "#             print(f\"For vehicle {node} in {G.nodes()} calculated control {[a_k,omega_k]}——from 'def GNN_prediction'\")\n",
    "            a_k=min(abs(a_k),a_max)*np.sign(a_k)\n",
    "            omega_k=min(abs(omega_k),omega_max)*np.sign(omega_k)\n",
    "            # 状态空间迭代\n",
    "            v_next=max(v_current+a_k*T_step,0)\n",
    "            theta_next=theta_current+omega_k*T_step\n",
    "            t_next=v_current*np.sin(theta_current)*T_step+t_current\n",
    "            s_next=v_current*np.cos(theta_current)*T_step+s_current\n",
    "            state_vehicle_single=[s_next,t_next,theta_next,v_next,a_k,omega_k]\n",
    "            state_vehicle_all[node].append(state_vehicle_single)\n",
    "            if s_next>0: # 车辆node穿越路段则植入True\n",
    "                crossing_flag_set.add(True)\n",
    "            else: # 车辆node未穿越路段则植入False\n",
    "                crossing_flag_set.add(False)\n",
    "#             print(f\"vehicle {node} state {state_vehicle_single} at {timestamp}th prediction——from 'def GNN_prediction'\")\n",
    "        if False not in crossing_flag_set: # 所有车辆都穿越了路段\n",
    "            break  \n",
    "#     print(f\"For graph {G.nodes()} final node {sorted_node_ids[-1]} will travel {L_traveling}m after {timestamp*T_step}s through prediction——from 'def GNN_prediction'\")\n",
    "    if timestamp>9000:\n",
    "        time.sleep(3)\n",
    "        print(f\"For graph {G.nodes()} target lane queue {node_index_Tlane} current lane queue {node_index_Clane} predicting too long——from 'def GNN_prediction'\")\n",
    "        time.sleep(3)\n",
    "        for print_i in state_vehicle_all:   \n",
    "            print(f\"vehicle {print_i} predicting {state_vehicle_all[print_i]}——from 'def GNN_prediction'\")\n",
    "            time.sleep(3)\n",
    "\n",
    "    return max(timestamp,1),state_vehicle_all\n",
    "\n",
    "def find_best_matching_graph(G0, T0, error_threshold=1):\n",
    "    \"\"\"\n",
    "    使用二分法逼近与目标时间 T0 匹配最佳的子图 G1。\n",
    "    \n",
    "    参数:\n",
    "        G0 (networkx.DiGraph): 完整的有向图。\n",
    "        T0 (float): 目标时间。\n",
    "        black_box_function (callable): 黑盒函数，输入为有向图，输出为时间 T。\n",
    "    \n",
    "    返回:\n",
    "        networkx.DiGraph: 与目标时间 T0 匹配最佳的子图 G1。\n",
    "    \"\"\"\n",
    "    # 按照节点的 'position' 属性由大到小排序\n",
    "    sorted_nodes = sorted(G0.nodes(data=True), key=lambda x: x[1]['position'], reverse=True)\n",
    "    \n",
    "    left = 0\n",
    "    original_right=len(sorted_nodes) - 1\n",
    "    right = original_right\n",
    "#   GNN估计通行平均车速\n",
    "#     speed_best = GNN_prediction(G0)\n",
    "#     _,dic_selected_initial=sorted_nodes[0]\n",
    "#     L0_initial=dic_selected_initial['position']\n",
    "#     T_total=L0_initial/speed_best\n",
    "#       GNN估计通行时间\n",
    "    T_total,state_fitting_best=GNN_prediction(G0)\n",
    "    error=abs(T_total-T0)\n",
    "    error_last=float('inf')\n",
    "    G_best=G0.copy()\n",
    "#     print(error_last >= error)\n",
    "    counter=0\n",
    "    while error_last-error>0.001 and error>=error_threshold:\n",
    "        error_last=error\n",
    "        mid = (left + right) // 2\n",
    "        # 从 G0 中删除前 mid 个节点获得G1\n",
    "        G1 = G0.copy()\n",
    "        for node, _ in sorted_nodes[:mid]:\n",
    "            G1.remove_node(node)\n",
    "        # 计算 G1 的时间 T：基于GNN平均车速\n",
    "#         _,dic_selected=sorted_nodes[min(mid+1,original_right)]\n",
    "#         L0=dic_selected['position']\n",
    "#         speed=GNN_prediction(G1)\n",
    "#         T = L0 / speed\n",
    "        # 计算 G1 的时间 T：基于GNN通行时间\n",
    "        T,state_fitting = GNN_prediction(G1)\n",
    "#         print(f'current time {T} with left {left}, right {right} and mid {mid}')\n",
    "        # 计算与 T0 的差值\n",
    "        error = abs(T - T0)\n",
    "        if error_last > error:\n",
    "            G_best=G1.copy()\n",
    "            state_fitting_best=state_fitting\n",
    "        # 二分法更新\n",
    "        if T>T0:\n",
    "            left = mid\n",
    "        else:\n",
    "            right = mid\n",
    "        if error_last==error:\n",
    "            counter=counter+1\n",
    "        if counter>10:\n",
    "            break\n",
    "\n",
    "#         print(f'Current error: {error}, Last error: {error_last}, Threshold: {error_threshold}')\n",
    "    \n",
    "    return G_best,state_fitting_best    \n",
    "    \n",
    "def self_predict_update(duration_time,updating_type,G_original,lane_set,final_nodes):\n",
    "    if len(G_original.nodes())==0 or duration_time<0.1:\n",
    "#         print(f\"for graph {G_original.nodes()} with duration {duration_time} prediction is non-necessary——from 'def self_predict_update'\")\n",
    "        return G_original,final_nodes\n",
    "    # 节点属性更新\n",
    "    lane_set=set()\n",
    "    if updating_type==0:# 排队状态下\n",
    "        _,state_predicting=GNN_prediction(G_original,round(duration_time/0.1),0)# 首排期望车速为0，为排队状态\n",
    "    else:# 通行状态\n",
    "        _,state_predicting=GNN_prediction(G_original,round(duration_time/0.1))\n",
    "    for node in G_original.nodes():\n",
    "        new_position =  -state_predicting[node][-1][0]\n",
    "        G_original.nodes[node]['position']=max(new_position,0.1)\n",
    "        lateral_pos=state_predicting[node][-1][1]\n",
    "        new_lane=round(lateral_pos/3)+G_original.nodes[node]['Clane'] # 以3为车道宽度估计车辆所在车道\n",
    "        if min(G_original.nodes[node]['Clane'],G_original.nodes[node]['Tlane'])<=new_lane<=max(G_original.nodes[node]['Clane'],G_original.nodes[node]['Tlane']):\n",
    "            G_original.nodes[node]['Clane']=new_lane\n",
    "        else:\n",
    "            G_original.nodes[node]['Clane']=np.random.choice([G_original.nodes[node]['Clane'],G_original.nodes[node]['Tlane'],G_original.nodes[node]['Tlane']])\n",
    "        new_speed=state_predicting[node][-1][3]\n",
    "        G_original.nodes[node]['speed']=new_speed\n",
    "        lane_set.add(G_original.nodes[node]['Clane'])\n",
    "    # 边更新\n",
    "    G_copy=G_original.copy()\n",
    "    G_original.remove_edges_from(G_copy.edges())\n",
    "    final_nodes_updated=final_nodes\n",
    "    for lane_index in list(sorted(lane_set)):    \n",
    "        vehicle_in_lane = sorted([node for node, attrs in G_original.nodes(data=True) if attrs.get('Clane') == lane_index],key=lambda node: G_original.nodes[node]['position'])\n",
    "        for i in range(len(vehicle_in_lane) - 1):\n",
    "            source = vehicle_in_lane[i]\n",
    "            target = vehicle_in_lane[i + 1]\n",
    "            G_original.add_edge(source, target,distance=G_original.nodes[target]['position']-G_original.nodes[source]['position'] )\n",
    "            final_nodes_updated[lane_index]=vehicle_in_lane[i + 1]\n",
    "    return G_original,final_nodes_updated\n",
    "\n",
    "\n",
    "def lane_distribution_prediction(possible_lane_dic,current_edge,net,DealedTL_dic,edge_search_dic,predicting_time,known_graph_dic={},known_edge_list=[]):\n",
    "    current_time=traci.simulation.getTime()\n",
    "    junction_id=current_edge.split(\"-\")[0]\n",
    "    terminal_junction=current_edge.split(\"-\")[1]\n",
    "    G_current_initial,lane_current,final_nodes_list=sample_based_graph_generation(current_edge,net)\n",
    "    G_current_complete=target_lane_initialize(G_current_initial,lane_current)# 初始化目标车道\n",
    "#     print(f\"final nodes:{final_nodes_list}--from 'def lane_distribution_prediction'\")\n",
    "    # 流出预测\n",
    "    G_predict_outgoing=G_current_complete.copy()\n",
    "    # 判定路口控制类别，计算预测域内的通行状态\n",
    "    if net.getNode(terminal_junction).getType()=='traffic_light':\n",
    "        T_queue=[]\n",
    "        state_flag=[]\n",
    "        _,holding_axis=holding_time_axis(terminal_junction,DealedTL_dic,predicting_time)\n",
    "        for index in range(len(holding_axis['Holding phase'])):\n",
    "            phase=holding_axis['Holding phase'][index]\n",
    "            duration=holding_axis['Ending point'][index]-holding_axis['Starting point'][index]\n",
    "            T_queue.append(duration)\n",
    "            if current_edge in DealedTL_dic[terminal_junction]['FromEdge list'][phase]:\n",
    "                state_flag.append(1)\n",
    "            else:\n",
    "                state_flag.append(0)   \n",
    "    else:\n",
    "        T_queue=[predicting_time]\n",
    "        state_flag=[1]\n",
    "    # 根据预测域内的通行状态更新当前路段车辆分布图\n",
    "    for i in range(len(T_queue)):\n",
    "        G_predict_outgoing,final_nodes_updated=self_predict_update(T_queue[i],state_flag[i],G_predict_outgoing,lane_current,final_nodes_list)\n",
    " \n",
    "    # 流入预测\n",
    "    G_predict_incoming=G_predict_outgoing.copy()\n",
    "    incoming_edges=net.getEdge(current_edge).getIncoming()\n",
    "    incoming_num=len(incoming_edges)\n",
    "#     print(f\"Incoming edge number: {incoming_num}--from 'def lane_distribution_prediction'\")\n",
    "    edge_list=[]\n",
    "    G_incoming_list=[]\n",
    "    final_nodes_list=[]\n",
    "    lanes_incoming_list=[]\n",
    "    state_flag_total=[]\n",
    "    for edge_ic in incoming_edges:\n",
    "        single_edge_ID=edge_ic.getID()\n",
    "        G_incoming_initial,lane_incoming,final_incoming=sample_based_graph_generation(single_edge_ID,net)\n",
    "        if len(G_incoming_initial.nodes())==0:\n",
    "#             print(f\"Empty incoming edge: {single_edge_ID}--from 'def lane_distribution_prediction'\")\n",
    "            incoming_num=incoming_num-1\n",
    "            continue\n",
    "        if single_edge_ID in known_edge_list:\n",
    "            G_incoming_complete=known_graph_dic[single_edge_ID]\n",
    "            if len(G_incoming_complete.nodes())==0:\n",
    "                incoming_num=incoming_num-1\n",
    "                continue\n",
    "        else:\n",
    "            G_incoming_complete=target_lane_initialize(G_incoming_initial,lane_incoming)# 初始化目标车道\n",
    "        edge_list.append(single_edge_ID)\n",
    "        state_flag_total.append([])\n",
    "        final_nodes_list.append(final_incoming)\n",
    "        G_incoming_list.append(G_incoming_complete)\n",
    "        lanes_incoming_list.append(lane_incoming)\n",
    "        \n",
    "    if net.getNode(junction_id).getType()=='traffic_light':\n",
    "        T_queue=[]\n",
    "        state_flag=[]\n",
    "        _,holding_axis=holding_time_axis(junction_id,DealedTL_dic,predicting_time)\n",
    "        for index in range(len(holding_axis['Holding phase'])):\n",
    "            phase=holding_axis['Holding phase'][index]\n",
    "            duration=holding_axis['Ending point'][index]-holding_axis['Starting point'][index]\n",
    "            T_queue.append(duration)\n",
    "            if current_edge in DealedTL_dic[junction_id]['ToEdge list'][phase]: # 至少存在一个edge_list[j]到current_edge的流入\n",
    "                for j in range(incoming_num):\n",
    "                    if edge_list[j] in DealedTL_dic[junction_id]['FromEdge list'][phase]:\n",
    "                        state_flag_total[j].append(2) # 从edge_list[j]到current_edge的流入阶段\n",
    "                    else:\n",
    "                        state_flag_total[j].append(1) # edge_list[j]不流入current_edge的阶段   \n",
    "            else: # 不存在任何edge_list[j]到current_edge的流入\n",
    "                for j in range(incoming_num):\n",
    "                    if edge_list[j] in DealedTL_dic[junction_id]['FromEdge list'][phase]: # 存在edge_list[j]互相之间的流入\n",
    "                        state_flag_total[j].append(1) # 由于路口交通规则的限制，edge_list[j]路段的流入并不会影响edge_list[j]路段的流出\n",
    "                    else:\n",
    "                        state_flag_total[j].append(0) # 红灯等待  \n",
    "    else:\n",
    "        T_queue=[predicting_time]\n",
    "        for j in range(incoming_num):\n",
    "            state_flag_total[j].append(2)\n",
    "    # 根据预测域内的通行状态更新当前路段车辆分布图\n",
    "#     print(f\"Incoming edges {edge_list}, predicted states {state_flag_total}--from 'def lane_distribution_prediction'\")\n",
    "#     print(f\" junction {junction_id} {len(T_queue)} phases {T_queue} predicted within horizon {predicting_time} with {incoming_num} incoming at {time.time()}--from 'def lane_distribution_prediction'\")\n",
    "    for i in range(len(T_queue)):\n",
    "        if T_queue[i]==0:\n",
    "            continue\n",
    "        for j in range(incoming_num):\n",
    "            if 2 not in state_flag_total[j][i:]: # 若后续不再存在到current_edge的流入阶段，则跳过对edge_list[j]路段的分布预测\n",
    "                continue\n",
    "#             print(f\"incoming {edge_list[j]} predicting with nodes {G_incoming_list[j].nodes()} at {time.time()}--from 'def lane_distribution_prediction'\")\n",
    "            if len(G_incoming_list[j].nodes())==0: # 若edge_list[j]已经滚动预测为空路段，则跳过\n",
    "                continue\n",
    "            if state_flag_total[j][i]==2:\n",
    "#                 print(f\"Incoming prediction of {edge_list[j]} begins--from 'def lane_distribution_prediction'\")\n",
    "                G_dynamic,state_fitting=find_best_matching_graph(G_incoming_list[j], T_queue[i])\n",
    "                crossing_map=edge_search_dic['Possible to lanes'][edge_list[j]][current_edge]\n",
    "#                 crossing_map=DealedTL_dic[junction_id]['FromLane list'][crossing_phase]# 以incoming车道ID为key，outgoing车道ID列表为value\n",
    "                # 从小到大排列\n",
    "                sorted_nodes = sorted(G_dynamic.nodes(data=True), key=lambda x: x[1]['position'], reverse=False)\n",
    "                for node,_ in sorted_nodes:\n",
    "                    incoming_lane=G_dynamic.nodes[node]['Tlane']\n",
    "                    if incoming_lane not in crossing_map:\n",
    "                        continue\n",
    "                    totoal_to_lanes=list(crossing_map[incoming_lane]) # set变量需要转为list变量\n",
    "                    to_lane=random.choice(totoal_to_lanes)\n",
    "                    int_lane_index=int(to_lane)\n",
    "#                     print(f\"Predicted lane: {int_lane_index} in {lane_current}, where final vehicles are {final_nodes_updated}--from 'def lane_distribution_prediction'\")\n",
    "                    final_node_located=final_nodes_updated[int_lane_index]\n",
    "                    max_s=net.getEdge(current_edge).getLength()\n",
    "                    last_position=G_dynamic.nodes[node]['position']\n",
    "                    traveling_distance=state_fitting[node][-1][0]# 读取预测的沿路坐标\n",
    "                    if final_node_located==None: # 驶入车道没有前车\n",
    "                        new_position = np.clip(traveling_distance, 0.1, max_s-0.1).astype(float)\n",
    "                        G_predict_incoming.add_node(node,Clane=int_lane_index,speed=state_fitting[node][-1][3],position=max_s-new_position)\n",
    "                        final_nodes_updated[int_lane_index]=node\n",
    "#                             G_current.add_node(vehicle,Clane=lane_index,speed=velocity_current,position=s_total-s_current)\n",
    "#                             G_current.add_edge(source, target,distance=G_current.nodes[target]['position']-G_current.nodes[source]['position'] )\n",
    "                    else:# 驶入车道有前车\n",
    "                        front_position=G_predict_incoming.nodes[final_node_located]['position'] # 已经过流出预测\n",
    "                        total_T_predicting=min(len(state_fitting[node]),max(round(round(T_queue[i]/0.1)-1),0))\n",
    "                        if total_T_predicting==0:\n",
    "                            print(f\"vehicle {node} in fitted graph {G_dynamic.nodes()} incoming within {T_queue[i]} is too fast——from 'def lane_distribution_prediction'\")\n",
    "                            index_i=0\n",
    "                            speed_located=G_dynamic.nodes[node]['speed']\n",
    "                            s_located=0\n",
    "                        else:\n",
    "                            \n",
    "                            for index_i in range(0,total_T_predicting):\n",
    "                                if state_fitting[node][index_i][0]>0:\n",
    "                                    break\n",
    "                            speed_located=state_fitting[node][index_i][3]\n",
    "                            s_located=state_fitting[node][index_i][0]\n",
    "                        distance_pre=max_s-front_position\n",
    "                        speed_pre=G_predict_incoming.nodes[final_node_located]['speed']\n",
    "                        distance_located=min(max(s_located,0.1),distance_pre-0.1)\n",
    "                        s_updated=distance_located\n",
    "                        v_updated=speed_located\n",
    "                        for _ in range(round(T_queue[i]/0.1)-index_i):\n",
    "                            a_k=0.5*(speed_pre-v_updated)+0.02*(distance_pre-s_updated-5-0.2*v_updated)\n",
    "                            v_updated=v_updated+a_k*0.1\n",
    "                            v_updated=max(v_updated,0)\n",
    "                            s_updated=s_updated+v_updated*0.1\n",
    "                        new_position = np.clip(max_s-s_updated, front_position+0.1,max_s-0.1 ).astype(float)\n",
    "                        G_predict_incoming.add_node(node,Clane=int_lane_index,speed=v_updated,position=new_position)\n",
    "                        source=final_nodes_updated[int_lane_index]\n",
    "                        target=node\n",
    "                        G_predict_incoming.add_edge(source, target,distance=G_predict_incoming.nodes[target]['position']-G_predict_incoming.nodes[source]['position'] )\n",
    "                        final_nodes_updated[int_lane_index]=node\n",
    "                    G_predict_incoming=target_lane_initialize(G_predict_incoming,lane_current)\n",
    "                G_incoming_list[j],final_nodes_list[j]=self_predict_update(T_queue[i],1,G_incoming_list[j],lanes_incoming_list[j],final_nodes_list[j])\n",
    "            else:\n",
    "                G_incoming_list[j],final_nodes_list[j]=self_predict_update(T_queue[i],state_flag_total[j][i],G_incoming_list[j],lanes_incoming_list[j],final_nodes_list[j])\n",
    "    return G_predict_incoming,G_predict_outgoing,final_nodes_updated,lane_current\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于模型预测控制的车辆实时调度（保证每次采样的动作不一致直至达到要求采样数，总采样次数大于等于设定值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample_action_combinations(N, actions, m):\n",
    "    \"\"\"\n",
    "    随机采样动作组合，直到采样数达到最大值m。\n",
    "\n",
    "    参数:\n",
    "        N (int): 智能体的数量。\n",
    "        actions (list of lists): 每个智能体的动作空间，actions[i] 是第 i 个智能体的动作列表。\n",
    "        m (int): 最大的采样数。\n",
    "\n",
    "    返回:\n",
    "        list of lists: 采样的所有动作组合。\n",
    "    \"\"\"\n",
    "    # 生成所有可能的动作组合\n",
    "    n_max=1\n",
    "    for i in actions:\n",
    "        n_max=n_max*len(i)\n",
    "#     print(f\"maximum action number:{n_max}\")\n",
    "    \n",
    "    # 如果m大于所有可能的组合数，则直接返回所有组合\n",
    "    \n",
    "    if m >= n_max:\n",
    "        all_combination=itertools.product(*actions)\n",
    "        return [list(comb) for comb in all_combination],1\n",
    "    else:\n",
    "        sampled_action_set=set()\n",
    "        sample_counter=0\n",
    "        while len(sampled_action_set)<m:\n",
    "            sample_counter=sample_counter+1\n",
    "            sampled_action=tuple(random.choice(actions[i]) for i in range(N))\n",
    "#             print(f\"sampled: {sampled_action}\")\n",
    "            sampled_action_set.add(sampled_action)\n",
    "#         print(f\"sample times: {sample_counter}\")\n",
    "        return [list(comb) for comb in sampled_action_set],sample_counter\n",
    "\n",
    "def two_step_MPC_prediction(net,DealedTL_dic,initialized_dic,control_dict,edge_search_dic,sample_number):\n",
    "    lane_constrain_dict=edge_search_dic['Possible from lanes']\n",
    "    possible_lane_dic=edge_search_dic['Possible to lanes']\n",
    "    current_edge=initialized_dic['Current edge']\n",
    "    lane_total=initialized_dic['Total lanes']\n",
    "    G_initial=initialized_dic['Initialized graph']\n",
    "#     print(G_initial.nodes())\n",
    "    obstacle_position=initialized_dic['Obstacle current lanes']\n",
    "    obstacle_target=initialized_dic['Obstacle target lanes']\n",
    "    vehicle_list=initialized_dic['Decision vehicles']\n",
    "    position_list=initialized_dic['Vehicle distances']\n",
    "    _,end_junction_id=current_edge.split(\"-\")\n",
    "    \n",
    "    T_preciting_list=[]\n",
    "    decisions_list=[]\n",
    "    decision_lanes_list=[]\n",
    "    predict_decisions_list=[]\n",
    "    # 预采样节点规划决策\n",
    "    total_action_space=[]\n",
    "    total_action_index_space=[]\n",
    "    for index_preact in range(len(vehicle_list)):\n",
    "        vehicle_i_preact=vehicle_list[index_preact]\n",
    "        node_i_preact=current_edge\n",
    "#         print(f\"sample of vehicle {vehicle_i_preact} on edge {node_i_preact} at {time.time()}--from 'def two_step_MPC_prediction'\")\n",
    "        if control_dict[vehicle_i_preact]['uk']==None: # 未决策/决策执行完的车辆，在剪枝后的动作空间中采样\n",
    "            action_space=control_dict[vehicle_i_preact]['action list'][control_dict[vehicle_i_preact]['stage']][node_i_preact]\n",
    "        else: # 决策执行中的车辆，第一步为执行中的决策，第二步为下一步采样\n",
    "            next_decision=control_dict[vehicle_i_preact]['uk']\n",
    "            next_action_space=control_dict[vehicle_i_preact]['detailed action dictionary'][control_dict[vehicle_i_preact]['stage']][next_decision]\n",
    "            action_space=[]\n",
    "            for i in next_action_space:\n",
    "                action_space.append([next_decision,i])\n",
    "        total_action_space.append(action_space)\n",
    "        total_action_index_space.append(list(range(len(action_space))))\n",
    "    actions_all,_ = random_sample_action_combinations(len(vehicle_list), total_action_index_space, sample_number)\n",
    "    # 遍历采样结果计算通行时间\n",
    "    sample_counter=0\n",
    "    message_step=20\n",
    "    time_zero=time.time()\n",
    "    for sampled_action_index in actions_all: # 多次采样\n",
    "        sample_counter=sample_counter+1\n",
    "        print(f\"!!!{sample_counter}th start at {time.time()-time_zero}!!!--from 'def two_step_MPC_prediction'\")\n",
    "        applied_decision={}\n",
    "        next_edge_list=[]\n",
    "        next_next_edge_dic={}\n",
    "        assign_position=[]\n",
    "        available_target=[]\n",
    "        # 采样节点规划决策\n",
    "        for index in range(len(vehicle_list)):\n",
    "            vehicle_i=vehicle_list[index]\n",
    "            node_i=current_edge\n",
    "            action_sample=total_action_space[index][sampled_action_index[index]]\n",
    "#             if control_dict[vehicle_i]['uk']==None: # 未决策/决策执行完的车辆，在剪枝后的动作空间中采样\n",
    "#                 action_space=control_dict[vehicle_i]['action list'][control_dict[vehicle_i]['stage']][node_i]\n",
    "#                 action_sample=random.choice(action_space)\n",
    "#             else: # 决策执行中的车辆，第一步为执行中的决策，第二步为下一步采样\n",
    "#                 next_decision=control_dict[vehicle_i]['uk']\n",
    "#                 action_sample=[next_decision,random.choice(control_dict[vehicle_i]['detailed action dictionary'][control_dict[vehicle_i]['stage']][next_decision])]\n",
    "            applied_decision[vehicle_i]=action_sample # 在可能的动作空间中进行多次随机采样\n",
    "#             print(f\"sampled action:{action_sample} of vehicle {vehicle_i} on edge {node_i}--from 'def two_step_MPC_prediction'\")\n",
    "            assign_position.append(G_initial.nodes[vehicle_i]['Clane'])\n",
    "            available_target.append(lane_constrain_dict[node_i][action_sample[0]])\n",
    "            next_edge_list.append(action_sample[0])\n",
    "            next_next_edge_dic[vehicle_i]=action_sample[1]\n",
    "        if sample_counter % message_step == 1:\n",
    "            print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")\n",
    "            print(f\"vehicle {vehicle_list} firstly initialize target lanes at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "        assigned_lane=lane_assignment_optimization(assign_position,obstacle_position,obstacle_target,available_target,lane_total)\n",
    "        for index in range(len(vehicle_list)):\n",
    "            vehicle_i=vehicle_list[index]\n",
    "            G_initial.nodes[vehicle_i]['Tlane']=assigned_lane[index]\n",
    "#         print(f\"decision graph:{G_initial} with nodes:{G_initial.nodes()}--from 'def two_step_MPC_prediction'\")\n",
    "        T_traveling_1,state_vehicle_dic_1=GNN_prediction(G_initial) # 基于采样的决策进行车道分配规划，计算通行时长\n",
    "        if sample_counter % message_step == 1:\n",
    "#             print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")\n",
    "            print(f\"first traveling time {T_traveling_1} calculated at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "        # 计算红绿灯路口等待时长\n",
    "        if net.getNode(end_junction_id).getType()=='traffic_light':\n",
    "            T_waitting_1=None\n",
    "            cycle_time=DealedTL_dic[end_junction_id]['Cycle time']\n",
    "            _,holding_axis=holding_time_axis(end_junction_id,DealedTL_dic,T_traveling_1+cycle_time)\n",
    "#             print(f\"predicting time:{T_traveling_1+cycle_time}--from 'def two_step_MPC_prediction'\")\n",
    "#             print(f\"predicted result:{holding_axis}--from 'def two_step_MPC_prediction'\")\n",
    "            for index in range(len(holding_axis['Holding phase'])):\n",
    "                phase=holding_axis['Holding phase'][index]\n",
    "                crossing_edge_list=DealedTL_dic[end_junction_id]['FromEdge list'][phase]\n",
    "#                 print(f\"current egde:{current_edge}, crossing list:{crossing_edge_list}--from 'def two_step_MPC_prediction'\")\n",
    "                if current_edge in crossing_edge_list and holding_axis['Ending point'][index]>=T_traveling_1:\n",
    "                    allowed_TL_time=holding_axis['Starting point'][index]\n",
    "                    T_waitting_1=max(allowed_TL_time-T_traveling_1,0)\n",
    "                    break\n",
    "            if T_waitting_1==None:\n",
    "                print(f'红绿灯路口{end_junction_id}等待时间计算出错:{current_edge}无法通过！')\n",
    "        else:\n",
    "            T_waitting_1=0\n",
    "        if sample_counter % message_step == 1:\n",
    "#             print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")\n",
    "            print(f\"first waitting time {T_waitting_1} calculated at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "        G_without_decision=G_initial.copy()\n",
    "        G_without_decision.remove_nodes_from(vehicle_list)\n",
    "        predict_edges_set=set()\n",
    "        G_predict_dic={}\n",
    "        final_nodes_dic={}\n",
    "        lanes_dic={}\n",
    "        vehicles_dic={}\n",
    "        decision_lanes_list_single=[]\n",
    "        if sample_counter % message_step == 1:\n",
    "#             print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")\n",
    "            print(f\"edges {next_edge_list} prediction begin at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "            \n",
    "        for index_i in range(len(next_edge_list)):\n",
    "            next_edge=next_edge_list[index_i]\n",
    "            max_s=net.getEdge(next_edge).getLength()\n",
    "            if next_edge in predict_edges_set:\n",
    "                G_predict=G_predict_dic[next_edge]\n",
    "                final_nodes_updated=final_nodes_dic[next_edge]\n",
    "                lane_current=lanes_dic[next_edge]\n",
    "            else:\n",
    "#                 print(f\"predicted edge:{next_edge}--from 'def two_step_MPC_prediction'\")\n",
    "#                                                                 lane_distribution_prediction(possible_lane_dic,current_edge,net,DealedTL_dic,edge_search_dic,predicting_time,known_graph_dic={},known_edge_list=[])\n",
    "                \n",
    "#                 print(f\"predicting edge:{next_edge}--from 'def two_step_MPC_prediction'\")\n",
    "                G_predict,_,final_nodes_updated,lane_current=lane_distribution_prediction(possible_lane_dic,next_edge,net,DealedTL_dic,edge_search_dic,T_traveling_1+T_waitting_1,{current_edge:G_without_decision},current_edge)\n",
    "                vehicles_dic[next_edge]=[]\n",
    "            ego_vehicle=vehicle_list[index_i]\n",
    "            possible_lane=possible_lane_dic[current_edge][next_edge][G_initial.nodes[ego_vehicle]['Tlane']] # set变量\n",
    "#             print(f\"possible lanes {possible_lane}--from 'def two_step_MPC_prediction'\")\n",
    "            arrive_lane=random.choice(list(possible_lane))\n",
    "            traveling_distance=state_vehicle_dic_1[ego_vehicle][-1][0]# 读取建模预测的沿路坐标，必然大于等于0，驶出了当前路段\n",
    "            current_s=G_initial.nodes[ego_vehicle]['position']\n",
    "            predict_position=max(max_s-traveling_distance,0.1)\n",
    "            predict_speed=state_vehicle_dic_1[ego_vehicle][-1][3]# 读取建模预测的车速\n",
    "#             print(f\"for node: {ego_vehicle} Clane:{arrive_lane},speed:{predict_speed},position:{predict_position}--from 'def two_step_MPC_prediction'\")    \n",
    "            G_predict.add_node(ego_vehicle,Clane=arrive_lane,speed=predict_speed,position=predict_position)\n",
    "            current_final=final_nodes_updated[arrive_lane]\n",
    "            if current_final==None:\n",
    "                final_nodes_updated[arrive_lane]=ego_vehicle\n",
    "            else:\n",
    "                G_predict.add_edge(current_final, ego_vehicle,distance=G_predict.nodes[ego_vehicle]['position']-G_predict.nodes[current_final]['position'] )\n",
    "                final_nodes_updated[arrive_lane]=ego_vehicle\n",
    "            predict_edges_set.add(next_edge)\n",
    "#             print(f\"predicted graph {G_predict}--from 'def two_step_MPC_prediction'\")\n",
    "            G_predict_dic[next_edge]=G_predict\n",
    "            final_nodes_dic[next_edge]=final_nodes_updated\n",
    "            lanes_dic[next_edge]=lane_current\n",
    "            vehicles_dic[next_edge].append(ego_vehicle)\n",
    "            decision_lanes_list_single.append(arrive_lane)\n",
    "        if sample_counter % message_step == 1:\n",
    "#             print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")\n",
    "            print(f\"edges {next_edge_list} prediction ended at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "            \n",
    "            # 在预测的路段车辆分布有向图中添加节点\n",
    "            # 在预测的路段车辆分布有向图中添加边\n",
    "        predicting_traveling_time_list=[]\n",
    "        predicting_waitting_time_list=[]\n",
    "        for key_index in G_predict_dic:\n",
    "            assign_position_after=[]\n",
    "            obstacle_position_after=[]\n",
    "            obstacle_target_after=[]\n",
    "            available_target_after=[]\n",
    "            G_selected=G_predict_dic[key_index]\n",
    "            lane_total_2=lanes_dic[key_index]\n",
    "#             print(f\"current graph:{G_selected} with nodes:{G_selected.nodes()}--from 'def two_step_MPC_prediction'\")\n",
    "            for node_i in G_selected.nodes():\n",
    "#                 print(f\"node {node_i} with Clane:{G_selected.nodes[node_i]['Clane']}--from 'def two_step_MPC_prediction'\")\n",
    "                if node_i in vehicles_dic[key_index]:\n",
    "                    assign_position_after.append(G_selected.nodes[node_i]['Clane'])\n",
    "                    next_next_edge=next_next_edge_dic[node_i]\n",
    "                    if next_next_edge==None: # 若采样的第一步到达了终点，第二步是None，则约束变为全车道\n",
    "                        available_target_after.append(lane_total_2)\n",
    "                    else:\n",
    "                        available_target_after.append(lane_constrain_dict[key_index][next_next_edge])\n",
    "                else:\n",
    "                    obstacle_position_after.append(G_selected.nodes[node_i]['Tlane'])\n",
    "                    obstacle_target_after.append(G_selected.nodes[node_i]['Tlane'])\n",
    "#             print(f\"assign position:{assign_position_after},lane space:{available_target_after}--from 'def two_step_MPC_prediction'\")\n",
    "#             print(f\"obstacle position:{obstacle_position_after},obstacle target:{obstacle_target_after}--from 'def two_step_MPC_prediction'\")\n",
    "            if sample_counter % message_step == 1:\n",
    "#                     print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")        \n",
    "                print(f\"vehicle {vehicle_list} secondly initialize target lanes on {key_index} at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "            assigned_lane=lane_assignment_optimization(assign_position,obstacle_position,obstacle_target,available_target,lane_total_2)\n",
    "            for num_index in range(len(vehicles_dic[key_index])):\n",
    "                ego_vehicle=vehicles_dic[key_index][num_index]\n",
    "                G_selected.nodes[ego_vehicle]['Tlane']=assigned_lane[num_index]\n",
    "            T_traveling_2,_=GNN_prediction(G_selected)\n",
    "            if sample_counter % message_step == 1:\n",
    "#                 print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")\n",
    "                print(f\"second traveling time {T_traveling_2} on {key_index} calculated at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "#             print(f\"calculated traveling time: {T_traveling_2}--from 'def two_step_MPC_prediction'\")\n",
    "            end_junction_id_2=key_index.split(\"-\")[1]\n",
    "            if net.getNode(end_junction_id_2).getType()=='traffic_light':\n",
    "                T_waitting_2=None\n",
    "                cycle_time_2=DealedTL_dic[end_junction_id_2]['Cycle time']\n",
    "                _,holding_axis_2=holding_time_axis(end_junction_id_2,DealedTL_dic,T_traveling_2+cycle_time_2)\n",
    "#                 print(f\"traveling time:{T_traveling_2}, cycle time: {cycle_time_2}--from 'def two_step_MPC_prediction'\")\n",
    "#                 print(f\"predicted result:{holding_axis_2}--from 'def two_step_MPC_prediction'\")\n",
    "                for index_2 in range(len(holding_axis_2['Holding phase'])):\n",
    "                    phase_2=holding_axis_2['Holding phase'][index_2]\n",
    "                    crossing_edge_list_2=DealedTL_dic[end_junction_id_2]['FromEdge list'][phase_2]\n",
    "#                     print(f\"current egde:{key_index}, crossing list:{crossing_edge_list}--from 'def two_step_MPC_prediction'\")\n",
    "                    if key_index in crossing_edge_list_2 and holding_axis_2['Ending point'][index_2]>=T_traveling_2:\n",
    "                        allowed_TL_time_2=holding_axis_2['Starting point'][index_2]\n",
    "                        T_waitting_2=max(allowed_TL_time_2-T_traveling_2,0)\n",
    "                        break\n",
    "                if T_waitting_2==None:\n",
    "                    print(f'红绿灯路口{end_junction_id_2}等待时间计算出错:{key_index}无法通过！')\n",
    "            else:\n",
    "                T_waitting_2=0\n",
    "            if sample_counter % message_step == 1:\n",
    "#                 print(f\"————————{sample_counter}th sample predicting————————--from 'def two_step_MPC_prediction'\")\n",
    "                print(f\"second waitting time {T_waitting_2} at {end_junction_id_2} calculated at {time.time()-time_zero}--from 'def two_step_MPC_prediction'\")\n",
    "        if sample_counter % message_step == 1:\n",
    "            print(f\"————————{sample_counter}th sample ended————————--from 'def two_step_MPC_prediction'\")\n",
    "        predicting_traveling_time_list.append(T_traveling_2)\n",
    "        predicting_waitting_time_list.append(T_traveling_2)\n",
    "#             print(f\"prediction of {sample_counter}th sample succeed--from 'def two_step_MPC_prediction'\")\n",
    "        T_taking_sample=T_traveling_1+T_waitting_1+np.mean(predicting_traveling_time_list)+np.mean(predicting_waitting_time_list)\n",
    "        T_preciting_list.append(T_taking_sample)\n",
    "        decisions_list.append(next_edge_list)\n",
    "        decision_lanes_list.append(decision_lanes_list_single)\n",
    "        predict_decisions_list.append(next_next_edge_dic)\n",
    "    return T_preciting_list,decisions_list,decision_lanes_list,predict_decisions_list\n",
    "\n",
    "\n",
    "def MPC_schedule(net,vehicle_id,control_dic,DealedTL_dic,edge_search_dic,sample_number=100):\n",
    "    current_lane_full=traci.vehicle.getLaneID(vehicle_id)\n",
    "#     print(f\"full lane ID:{current_lane_full} of vehicle:{vehicle_id}--from 'def MPC_schedule'\")\n",
    "    if current_lane_full.split(\"_\")[0]==':10':\n",
    "        edge_id='10-11'\n",
    "        reading_lane_index=int(traci.vehicle.getLaneIndex(vehicle_id))\n",
    "        if reading_lane_index==0:\n",
    "            lane_index_src='0'\n",
    "        elif reading_lane_index==1 or reading_lane_index==2:\n",
    "            lane_index_src='1'\n",
    "        else:\n",
    "            lane_index_src='2'\n",
    "    elif current_lane_full.split(\"_\")[0]==':11':\n",
    "        edge_id='11-10'\n",
    "        reading_lane_index=int(traci.vehicle.getLaneIndex(vehicle_id))\n",
    "        if reading_lane_index==0:\n",
    "            lane_index_src='0'\n",
    "        elif reading_lane_index==1 or reading_lane_index==2:\n",
    "            lane_index_src='1'\n",
    "        else:\n",
    "            lane_index_src='2'\n",
    "    else:\n",
    "        edge_id,lane_index_src=current_lane_full.split(\"_\")\n",
    "    \n",
    "    G_current_initial,lane_current,_=sample_based_graph_generation(edge_id,net)\n",
    "    grouped_nodes,grouped_targets=group_nodes_by_position(G_current_initial, 'position','position', 10)\n",
    "    nodes_to_remain=[]\n",
    "    for i in range(len(grouped_nodes)):\n",
    "        selected_group=grouped_nodes[i]\n",
    "        selected_targets=grouped_targets[i]\n",
    "        nodes_to_remain=nodes_to_remain+selected_group\n",
    "        if vehicle_id in selected_group:\n",
    "            break\n",
    "    G_remove=G_current_initial.copy()\n",
    "    G_remove.remove_nodes_from(nodes_to_remain)\n",
    "    nodes_to_remove=list(G_remove.nodes())\n",
    "    G_current_initial.remove_nodes_from(nodes_to_remove)\n",
    "    obstacle_position=[]\n",
    "    obstacle_target=[]\n",
    "    for j in range(i+1):\n",
    "        for node_selected in grouped_nodes[j]:\n",
    "            assign_position=[G_current_initial.nodes[node_selected]['Clane']]\n",
    "            if control_dict[node_selected]['Tlane']==None:\n",
    "#                 print(f'assign position:{assign_position}, lane space:{lane_current}')\n",
    "                assigned_lane=lane_assignment_optimization(assign_position,obstacle_position,obstacle_target,[lane_current],lane_current)\n",
    "                G_current_initial.nodes[node_selected]['Tlane']=assigned_lane[0]\n",
    "            else:\n",
    "                assigned_lane=control_dict[node_selected]['Tlane']\n",
    "                G_current_initial.nodes[node_selected]['Tlane']=assigned_lane\n",
    "            obstacle_position=obstacle_position+assign_position\n",
    "            obstacle_target=obstacle_target+assigned_lane\n",
    "    print(f\"vehicles:{selected_group} on edge:{edge_id} begin MPC at {time.time()}--from 'def MPC_schedule'\")\n",
    "    initialized_dic={'Decision vehicles':selected_group,'Vehicle distances':selected_targets,'Current edge':edge_id,'Total lanes':lane_current,'Initialized graph':G_current_initial,'Obstacle current lanes':obstacle_position,'Obstacle target lanes':obstacle_target}\n",
    "    T_preciting_list,decisions_list,decision_lanes_list,predict_decisions_list=two_step_MPC_prediction(net,DealedTL_dic,initialized_dic,control_dic,edge_search_dic,sample_number)\n",
    "    min_value = min(T_preciting_list)\n",
    "    min_index = T_preciting_list.index(min_value)\n",
    "#     print(f\"optimal index:{min_index},MPC time:{T_preciting_list},MPC u:{decisions_list},MPC lane:{decision_lanes_list}--from 'def MPC_schedule'\")\n",
    "    optimal_decision=decisions_list[min_index]\n",
    "    optimal_Tlane=decision_lanes_list[min_index]\n",
    "    optimal_next_decision=predict_decisions_list[min_index]\n",
    "    for index in range(len(selected_group)):\n",
    "        vehicle_current=selected_group[index]\n",
    "        decision_current=optimal_decision[index]\n",
    "        predict_decision_current=optimal_next_decision[vehicle_current]\n",
    "        Tlane_current=optimal_Tlane[index]\n",
    "        control_dic[vehicle_current]['uk']=decision_current\n",
    "        control_dic[vehicle_current]['Tlane']=Tlane_current\n",
    "        if predict_decision_current==None:\n",
    "            control_dic[vehicle_current]['Route']=[edge_id,decision_current]\n",
    "        else:\n",
    "            control_dic[vehicle_current]['Route']=[edge_id,decision_current,predict_decision_current]\n",
    "#     print(f\"optimal decision:{optimal_decision} on {edge_id} of vehicle {selected_group}--from 'def MPC_schedule'\")\n",
    "    vehicle_id_index=selected_group.index(vehicle_id)\n",
    "    decision_vehicle_id=optimal_decision[vehicle_id_index]\n",
    "    Tlane_vehicle_id=optimal_Tlane[vehicle_id_index]\n",
    "    print(f\"MPC succeed at {time.time()}--from 'def MPC_schedule'\")\n",
    "    clear_output(wait=True)\n",
    "    return vehicle_id,decision_vehicle_id,Tlane_vehicle_id\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMO启动脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO终端已关闭\n"
     ]
    }
   ],
   "source": [
    "# 关闭TraCI连接\n",
    "traci.close()\n",
    "print(\"SUMO终端已关闭\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DJT/DJL离线baseline仿真与记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_traffic_lights_randomly(tl_id):\n",
    "    \"\"\"\n",
    "    随机初始化指定交通灯的初始相位。\n",
    "    \n",
    "    参数:\n",
    "    tl_id (str): 交通灯的ID\n",
    "    \"\"\"\n",
    "    # 获取交通灯的所有相位信息\n",
    "    logics = traci.trafficlight.getAllProgramLogics(tl_id)\n",
    "    logic = logics[0]  # 获取第一个控制方案\n",
    "    phases = logic.phases  # 获取所有相位\n",
    "    \n",
    "    # 随机选择一个相位作为初始相位\n",
    "    initial_phase_index = random.randint(0, len(phases) - 1)\n",
    "    traci.trafficlight.setPhase(tl_id, initial_phase_index)\n",
    "    \n",
    "    # 输出选择的初始相位信息\n",
    "    return initial_phase_index\n",
    "def initialize_traffic_lights_userdefined(tl_id,tl_initialize_dic):\n",
    "    traci.trafficlight.setPhase(tl_id, tl_initialize_dic[tl_id])\n",
    "    return tl_initialize_dic[tl_id]\n",
    "    \n",
    "\n",
    "def run_simulation(sumocfg_file,tl_initialize_dic,random_flag=True):\n",
    "    \"\"\"\n",
    "    运行SUMO仿真。\n",
    "    \n",
    "    参数:\n",
    "    sumocfg_file (str): SUMO配置文件的路径\n",
    "    \"\"\"\n",
    "    # 启动SUMO仿真\n",
    "#     traci.start(['sumo-gui', '-c', sumocfg_file])\n",
    "    traci.start(['sumo-gui', '-c', sumocfg_file, '--step-length', '0.1'])\n",
    "    # 获取所有交通灯的ID\n",
    "    tls_ids = traci.trafficlight.getIDList()\n",
    "    \n",
    "    # 随机初始化每个交通灯的初始相位\n",
    "    DealedTL_dic={}\n",
    "    initialized_traffic_lights={}\n",
    "    for tl_id in tls_ids:\n",
    "        if random_flag:\n",
    "            initialized_traffic_lights[tl_id]=initialize_traffic_lights_randomly(tl_id)\n",
    "        else:\n",
    "            initialized_traffic_lights[tl_id]=initialize_traffic_lights_userdefined(tl_id,tl_initialize_dic)\n",
    "                \n",
    "    # 运行仿真\n",
    "    MPC_counter=0\n",
    "    while traci.simulation.getMinExpectedNumber() > 0:\n",
    "        traci.simulationStep()\n",
    "        current_time = traci.simulation.getTime()\n",
    "#         print(f'Current time: {current_time}')\n",
    "    \n",
    "    # 关闭TraCI连接\n",
    "    traci.close()\n",
    "    print(\"SUMO终端已关闭\")\n",
    "    return initialized_traffic_lights\n",
    "\n",
    "# output_path_config= f\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases{simulating_data_index}.pkl\" \n",
    "# with open(output_path_config, 'rb') as file:\n",
    "#     tl_initialize_dic = pickle.load(file)\n",
    "# print(f\"{output_path_config}数据已加载\")\n",
    "# # SUMO配置文件路径\n",
    "# sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJL.sumocfg\"\n",
    "# # sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJT.sumocfg\"\n",
    "# # sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_mix.sumocfg\"\n",
    "# # sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\proposed_DMPC.sumocfg\"\n",
    "\n",
    "# # 运行仿真\n",
    "# start_time = time.time()\n",
    "# initialized_traffic_lights=run_simulation(sumocfg_file,tl_initialize_dic,False)#True：随机生成初始红绿灯相位并保存/False：载入已有配置\n",
    "# end_time = time.time()      \n",
    "# elapsed_time = end_time - start_time\n",
    "# output_file_path_light = r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases_copy.pkl\"  # 替换为你想要保存的文件名\n",
    "# with open(output_file_path_light, 'wb') as file:\n",
    "#     pickle.dump(initialized_traffic_lights, file)\n",
    "# print(f\"测试耗时：{elapsed_time}秒，数据已保存到：{output_file_path_light}\")\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "from scipy.io import savemat\n",
    "\n",
    "# 读取xml文件，写入excel\n",
    "def datadeal(file_xml):\n",
    "    vehicle_indicator={}\n",
    "    vehicle_dataframe={}\n",
    "    frame_indicator={}\n",
    "    vehicle_set=set()\n",
    "    for event, elem in ET.iterparse(file_xml, events=('end',)):\n",
    "        if elem.tag == 'timestep':\n",
    "            time = elem.get('time')\n",
    "            if float(time)%500==0:\n",
    "                print(f\"processing time {time}\")\n",
    "            vehicle_num_current=0\n",
    "            vehicle_speed_current=0\n",
    "            for vehicle in elem.findall('vehicle'):\n",
    "                vehicle_id = vehicle.get('id')\n",
    "                if vehicle_id not in vehicle_set:\n",
    "                    vehicle_set.add(vehicle_id)\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']={}\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['time']=[]\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['x']=[]\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['y']=[]\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['speed']=[]\n",
    "                x_num = vehicle.get('x')\n",
    "                y_num = vehicle.get('y')\n",
    "                speed = vehicle.get('speed')\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['time'].append(float(time))\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['x'].append(float(x_num))\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['y'].append(float(y_num))\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['speed'].append(float(speed))\n",
    "                vehicle_num_current=vehicle_num_current+1\n",
    "                vehicle_speed_current=vehicle_speed_current+float(speed)\n",
    "            frame_indicator[f'time_{int(float(time)*1000)}_ms']=np.array([vehicle_num_current,vehicle_speed_current/max(vehicle_num_current,1)])\n",
    "            elem.clear()\n",
    "    for vehicle_id_ind in vehicle_dataframe:\n",
    "        start_time=min(vehicle_dataframe[vehicle_id_ind]['time'])\n",
    "        end_time=max(vehicle_dataframe[vehicle_id_ind]['time'])\n",
    "        total_speed=sum(vehicle_dataframe[vehicle_id_ind]['speed'])\n",
    "        x_list=vehicle_dataframe[vehicle_id_ind]['x']\n",
    "        diff_x=[x_list[i+1] - x_list[i] for i in range(len(x_list) - 1)]\n",
    "        y_list=vehicle_dataframe[vehicle_id_ind]['x']\n",
    "        diff_y=[y_list[i+1] - y_list[i] for i in range(len(y_list) - 1)]\n",
    "        distance_step=[a**2 + b**2 for a, b in zip(diff_x, diff_y)]\n",
    "        vehicle_indicator[vehicle_id_ind]={}\n",
    "        vehicle_indicator[vehicle_id_ind]['appear']=start_time\n",
    "        vehicle_indicator[vehicle_id_ind]['disappear']=end_time\n",
    "        vehicle_indicator[vehicle_id_ind]['distance']=sum(distance_step)\n",
    "        vehicle_indicator[vehicle_id_ind]['averaspeed']=sum(distance_step)/(end_time-start_time)\n",
    "        vehicle_dataframe[vehicle_id_ind]['time']=np.array(vehicle_dataframe[vehicle_id_ind]['time'])\n",
    "        vehicle_dataframe[vehicle_id_ind]['x']=np.array(vehicle_dataframe[vehicle_id_ind]['x'])\n",
    "        vehicle_dataframe[vehicle_id_ind]['y']=np.array(vehicle_dataframe[vehicle_id_ind]['y'])\n",
    "        vehicle_dataframe[vehicle_id_ind]['speed']=np.array(vehicle_dataframe[vehicle_id_ind]['speed'])\n",
    "\n",
    "    # 关闭文件\n",
    "    return vehicle_indicator,frame_indicator,vehicle_dataframe\n",
    "\n",
    "simulating_data_index = 14\n",
    "output_path_config= f\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases{simulating_data_index}.pkl\" \n",
    "with open(output_path_config, 'rb') as file:\n",
    "    tl_initialize_dic = pickle.load(file)\n",
    "print(f\"{output_path_config}数据已加载\")\n",
    "# SUMO配置文件路径\n",
    "# sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJL.sumocfg\"\n",
    "sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJT.sumocfg\"\n",
    "# 运行仿真\n",
    "start_time = time.time()\n",
    "initialized_traffic_lights=run_simulation(sumocfg_file,tl_initialize_dic,False)#True：随机生成初始红绿灯相位并保存/False：载入已有配置\n",
    "end_time = time.time()      \n",
    "elapsed_time = end_time - start_time\n",
    "# 设置文件路径\n",
    "source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\"  # 源文件夹路径\n",
    "#     xml_file_path = os.path.join(source_folder, 'fcd_DJL.xml')\n",
    "xml_file_path = os.path.join(source_folder, 'fcd_DJT.xml')\n",
    "\n",
    "\n",
    "# indexes_select=[7,18]\n",
    "# # indexes_select=[18]\n",
    "# full_dealed_data={}\n",
    "# for simulating_data_index in indexes_select:\n",
    "#     # 设置文件路径\n",
    "#     # simulating_data_index = 9\n",
    "#     output_path_config= f\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases{simulating_data_index}.pkl\" \n",
    "#     with open(output_path_config, 'rb') as file:\n",
    "#         tl_initialize_dic = pickle.load(file)\n",
    "#     print(f\"{output_path_config}数据已加载\")\n",
    "#     # SUMO配置文件路径\n",
    "#     sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJL.sumocfg\"\n",
    "# #     sumocfg_file = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJT.sumocfg\"\n",
    "#     # 运行仿真\n",
    "#     start_time = time.time()\n",
    "#     initialized_traffic_lights=run_simulation(sumocfg_file,tl_initialize_dic,False)#True：随机生成初始红绿灯相位并保存/False：载入已有配置\n",
    "#     end_time = time.time()      \n",
    "#     elapsed_time = end_time - start_time\n",
    "#     # 设置文件路径\n",
    "#     source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\"  # 源文件夹路径\n",
    "# #     xml_file_path = os.path.join(source_folder, 'fcd_DJL.xml')\n",
    "#     xml_file_path = os.path.join(source_folder, 'fcd_DJT.xml')\n",
    "#     # 调用函数\n",
    "#     print(f\"{xml_file_path} converting\")\n",
    "#     vehicle_indicator,frame_indicator,vehicle_dataframe=datadeal(xml_file_path)\n",
    "#     full_dealed_data[f'file_{simulating_data_index}']={}\n",
    "#     full_dealed_data[f'file_{simulating_data_index}']['vehicle_indicator']=vehicle_indicator\n",
    "#     full_dealed_data[f'file_{simulating_data_index}']['frame_indicator']=frame_indicator\n",
    "#     full_dealed_data[f'file_{simulating_data_index}']['dataframes']=vehicle_dataframe\n",
    "#     clear_output(wait=True)\n",
    "#     single_dealed_data={}\n",
    "#     single_dealed_data['vehicle_indicator']=vehicle_indicator\n",
    "#     single_dealed_data['frame_indicator']=frame_indicator\n",
    "#     single_dealed_data['dataframes']=vehicle_dataframe\n",
    "# #     with open(f\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\DJL_data_{simulating_data_index}.pkl\", 'wb') as file:\n",
    "#     with open(f\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\DJT_data_{simulating_data_index}.pkl\", 'wb') as file:\n",
    "#         pickle.dump(single_dealed_data, file)\n",
    "#     print(f\"测试耗时：{elapsed_time}秒，数据已保存：{xml_file_path}\")\n",
    "    \n",
    "# # save_path = r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\DJL_data.pkl\"  # 替换为你想要保存的文件名\n",
    "# save_path = r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\DJT_data.pkl\"  # 替换为你想要保存的文件名\n",
    "# with open(save_path, 'wb') as file:\n",
    "#     pickle.dump(full_dealed_data, file)\n",
    "# print(f\"数据已保存到：{save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DMPC仿真与记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_traffic_lights_randomly(tl_id):\n",
    "    \"\"\"\n",
    "    随机初始化指定交通灯的初始相位。\n",
    "    \n",
    "    参数:\n",
    "    tl_id (str): 交通灯的ID\n",
    "    \"\"\"\n",
    "    # 获取交通灯的所有相位信息\n",
    "    logics = traci.trafficlight.getAllProgramLogics(tl_id)\n",
    "    logic = logics[0]  # 获取第一个控制方案\n",
    "    phases = logic.phases  # 获取所有相位\n",
    "    \n",
    "    # 随机选择一个相位作为初始相位\n",
    "    initial_phase_index = random.randint(0, len(phases) - 1)\n",
    "    traci.trafficlight.setPhase(tl_id, initial_phase_index)\n",
    "    return initial_phase_index\n",
    "\n",
    "def initialize_traffic_lights_userdefined(tl_id,tl_initialize_dic):\n",
    "    traci.trafficlight.setPhase(tl_id, tl_initialize_dic[tl_id])\n",
    "    return tl_initialize_dic[tl_id]\n",
    "\n",
    "def run_simulation(sumocfg_file,net,control_dic,G_total_dict,targets_dict,edge_search_dic,tl_initialize_dic,random_flag=True,sample_number=100):\n",
    "    \"\"\"\n",
    "    运行SUMO仿真。\n",
    "    \n",
    "    参数:\n",
    "    sumocfg_file (str): SUMO配置文件的路径\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    # 启动SUMO仿真\n",
    "#     traci.start(['sumo-gui', '-c', sumocfg_file])\n",
    "    traci.start(['sumo-gui', '-c', sumocfg_file, '--step-length', '0.1'])\n",
    "    # 获取所有交通灯的ID\n",
    "    tls_ids = traci.trafficlight.getIDList()\n",
    "    \n",
    "    # 随机初始化每个交通灯的初始相位\n",
    "    DealedTL_dic={}\n",
    "    for tl_id in tls_ids:\n",
    "        # 初始化数据字典\n",
    "        key_tl,value_tl=trafficlight_dic_generation(tl_id)\n",
    "#         print(f'trafficlight id: {tl_id}, applied id: {key_tl}')\n",
    "        DealedTL_dic[key_tl]=value_tl\n",
    "        if random_flag:\n",
    "            initialize_traffic_lights_randomly(tl_id)\n",
    "        else:\n",
    "            initialize_traffic_lights_userdefined(tl_id,tl_initialize_dic)\n",
    "    # 运行仿真\n",
    "    step = 0\n",
    "    MPC_counter=0\n",
    "#     last_message=None\n",
    "    edge_id_last={}\n",
    "    while traci.simulation.getMinExpectedNumber() > 0:\n",
    "        if step % 1 == 0:\n",
    "            vehicles_all=traci.vehicle.getIDList()\n",
    "            # 检查所有车辆是否执行至决策点，重置对应动作\n",
    "            for vehicle_i_1 in vehicles_all:\n",
    "                edge_id_1 = traci.vehicle.getRoadID(vehicle_i_1)\n",
    "#                 if vehicle_i_1=='14' and edge_id_1!=last_message:\n",
    "#                     last_message=edge_id_1\n",
    "#                     print(f\"at {traci.simulation.getTime()}s vehicle {vehicle_i_1} on {edge_id_1} where route {control_dic[vehicle_i_1]['Route']} and stage {control_dic[vehicle_i_1]['stage']} with targets {targets_dict[vehicle_i_1]}\")\n",
    "                if edge_id_1==':11_0':\n",
    "                    edge_id_1='11-10'\n",
    "                elif edge_id_1==':10_8':\n",
    "                    edge_id_1='10-11'\n",
    "                \n",
    "                # 在车辆移动过程中记录实际移动的路线\n",
    "                if not edge_id_1.startswith(\":\") and (edge_id_1 not in control_dic[vehicle_i_1]['recorded route'] or edge_id_1!=edge_id_last[vehicle_i_1]):\n",
    "                    control_dic[vehicle_i_1]['recorded route'].append(edge_id_1)\n",
    "                    edge_id_last[vehicle_i_1]=edge_id_1\n",
    "                if edge_id_1 in control_dic[vehicle_i_1]['Route'] and edge_id_1!=control_dic[vehicle_i_1]['Route'][0]:\n",
    "                    control_dic[vehicle_i_1]['uk']=None\n",
    "                    control_dic[vehicle_i_1]['Tlane']=None\n",
    "#                     if edge_id_1==targets_dict[vehicle_i_1][control_dic[vehicle_i_1]['stage']]:\n",
    "                    if edge_id_1==targets_dict[vehicle_i_1][control_dic[vehicle_i_1]['stage']]:\n",
    "                        control_dic[vehicle_i_1]['stage']=control_dic[vehicle_i_1]['stage']+1\n",
    "                        # 若移动至最后一个终点路段，则视为到达终点，在调度过程中忽略该车辆\n",
    "                        if control_dic[vehicle_i_1]['stage']>=len(targets_dict[vehicle_i_1]):\n",
    "                            print(f\"deleted vehicle { vehicle_i_1} with finished traveling\")\n",
    "                            traci.vehicle.remove(vehicle_i_1)   \n",
    "                else:\n",
    "                    continue\n",
    "            vehicles_all_updated=traci.vehicle.getIDList()\n",
    "            # MPC求解决策，更新动作\n",
    "            for vehicle_i_2 in vehicles_all_updated:\n",
    "                edge_id_2 = traci.vehicle.getRoadID(vehicle_i_2)\n",
    "                if edge_id_2==':11_0':\n",
    "                    edge_id_2='11-10'\n",
    "                elif edge_id_2==':10_8':\n",
    "                    edge_id_2='10-11'\n",
    "                if control_dic[vehicle_i_2]['uk']==None and not edge_id_2.startswith(\":\"):\n",
    "#                     print(f\"vehicle {vehicle_i_2} begins MPC scheduling on {edge_id_2}\")\n",
    "                    vehicle_id_now,decision_now,Tlane_now=MPC_schedule(net,vehicle_i_2,control_dic,DealedTL_dic,edge_search_dic,sample_number)\n",
    "                    control_dic[vehicle_id_now]['uk']=decision_now\n",
    "                    control_dic[vehicle_id_now]['Tlane']=Tlane_now\n",
    "                    MPC_counter=MPC_counter+1\n",
    "                else:\n",
    "                    continue\n",
    "            # 执行决策动作\n",
    "            for vehicle_i_3 in vehicles_all_updated:\n",
    "                edge_id_3 = traci.vehicle.getRoadID(vehicle_i_3)\n",
    "                current_route=list(traci.vehicle.getRoute(vehicle_i_3))\n",
    "                \n",
    "#                 print(f\"route reading:{current_route}, route writting:{control_dic[vehicle_i_3]['Route']}, comparison: {control_dic[vehicle_i_3]['Route']==current_route} \")\n",
    "#                 if edge_id_3==':10_8' and '11-12' not in control_dic[vehicle_i_3]['Route']: # 边10-11和11-10极小，无法读取车辆位置，需要特殊处理\n",
    "#                     control_dic[vehicle_i_3]['Route'].append('11-12')\n",
    "#                 elif edge_id_3==':11_0':\n",
    "#                     append_flag=True\n",
    "#                     avaliable_actions=control_dic[vehicle_i_3]['detailed action dictionary'][control_dict[vehicle_i_3]['stage']]['11-10']\n",
    "#                     for action_i in avaliable_actions:\n",
    "#                         if action_i==None:\n",
    "#                             continue\n",
    "#                         if action_i in control_dic[vehicle_i_3]['Route']:\n",
    "#                             append_flag=False\n",
    "#                             break\n",
    "#                     if append_flag:\n",
    "#                         selected_action=random.choice(avaliable_actions)\n",
    "#                         control_dic[vehicle_i_3]['Route'].append(selected_action)\n",
    "                if edge_id_3==':11_0':\n",
    "                    edge_id_3='11-10'\n",
    "                elif edge_id_3==':10_8':\n",
    "                    edge_id_3='10-11'\n",
    "                if control_dic[vehicle_i_3]['Route']==current_route or edge_id_3.startswith(\":\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    next_edge=control_dic[vehicle_i_3]['uk']\n",
    "                    instant_route=control_dic[vehicle_i_3]['Route']\n",
    "#                     print(f\"optimized route {instant_route} on {edge_id_3} of vehicle {vehicle_i_3}\")\n",
    "                    traci.vehicle.setRoute(vehicle_i_3, instant_route)\n",
    "        traci.simulationStep()\n",
    "        current_time = traci.simulation.getTime()\n",
    "#         print(f'Current time: {current_time}')\n",
    "        step += 1\n",
    "    end_time = time.time()      \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"耗时{elapsed_time}秒\")\n",
    "    # 关闭TraCI连接\n",
    "    traci.close()\n",
    "    print(f\"SUMO终端已关闭\")\n",
    "    return MPC_counter\n",
    "\n",
    "# 选择初始相位数据组\n",
    "simulating_data_index=2\n",
    "\n",
    "seleted_indexes_list_global=database_baseline['Routes index list']\n",
    "# print(seleted_indexes_list)\n",
    "G_total_dict_global={}\n",
    "targets_dict_global={}\n",
    "vehicle_ids_global=[]\n",
    "for iteration_index_global in range(len(seleted_indexes_list_global)):\n",
    "    vehicle_index_global=seleted_indexes_list_global[iteration_index_global]\n",
    "    vehicle_id_global=str(iteration_index_global)\n",
    "    current_data_index_global=seleted_indexes_list_global[vehicle_index_global]\n",
    "    G_list_global=database_dic[vehicle_index_global]['Graph list']\n",
    "    G_total_dict_global[vehicle_id_global]=G_list_global\n",
    "    indexed_target_single_global=database_dic[vehicle_index_global]['Indexed Targets']\n",
    "    targets_dict_global[vehicle_id_global]=indexed_target_single_global\n",
    "    vehicle_ids_global.append(vehicle_id_global)  \n",
    "net_global = sumolib.net.readNet(\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\sourceCICT.net.xml\")\n",
    "control_dic_global=control_dictionary_initialize(G_total_dict_global,targets_dict_global,vehicle_ids_global)\n",
    "edge_search_dic_global=lane_set_generation(net_global)\n",
    "# 交通灯初始配置\n",
    "# output_path_config_global= r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases2.pkl\" \n",
    "output_path_config_global= f\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases{simulating_data_index}.pkl\"\n",
    "with open(output_path_config_global, 'rb') as file:\n",
    "    tl_initialize_dic_global = pickle.load(file)\n",
    "print(f\"{output_path_config_global}数据已加载\")\n",
    "# SUMO配置文件路径\n",
    "sumocfg_file_global = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJL.sumocfg\"\n",
    "# 运行仿真\n",
    "start_time_global = time.time()\n",
    "MPC_counter_global=run_simulation(sumocfg_file_global,net_global,control_dic_global,G_total_dict_global,targets_dict_global,edge_search_dic_global,tl_initialize_dic_global,False,100)\n",
    "end_time_global = time.time()      \n",
    "elapsed_time_global = end_time_global - start_time_global\n",
    "print(f\"{len(seleted_indexes_list_global)}辆规模，{MPC_counter_global}车次MPC调度，共运行耗时：{elapsed_time_global}\")\n",
    "output_file_path_global = r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\route_MPC2.pkl\"  # 替换为你想要保存的文件名\n",
    "with open(output_file_path_global, 'wb') as file:\n",
    "    pickle.dump(control_dic_global, file)\n",
    "print(f\"数据已保存到：{output_file_path_global}\")\n",
    "\n",
    "# 结果数据储存\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 定义文件夹名称和文件路径\n",
    "folder_name = f\"DMPC_DJLBased_result{simulating_data_index}\"  # 新建的文件夹名称\n",
    "files_to_move =['fcd_DJL.xml','queue_DJL.xml','recorded_route_DJL.xml'] # 要移动的文件名称\n",
    "source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\" # 源文件夹路径\n",
    "address = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\"  # 新建文件夹的路径\n",
    "\n",
    "# 创建目标文件夹（如果文件夹不存在）\n",
    "target_folder = os.path.join(address, folder_name)\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "    print(f\"文件夹 '{target_folder}' 创建成功。\")\n",
    "else:\n",
    "    print(f\"文件夹 '{target_folder}' 已存在。\")\n",
    "\n",
    "# 移动文件\n",
    "for file_name in files_to_move:\n",
    "    source_path = os.path.join(source_folder, file_name)  # 源文件路径\n",
    "    destination_path = os.path.join(target_folder, file_name)  # 目标文件路径\n",
    "\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.move(source_path, destination_path)\n",
    "        print(f\"文件 '{file_name}' 已成功从 '{source_folder}' 移入文件夹 '{target_folder}'。\")\n",
    "    else:\n",
    "        print(f\"文件 '{file_name}' 在 '{source_folder}' 中不存在，无法移动。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCDR在线baseline仿真与记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SUMO\\work\\rebuild2\\InitialPhases14.pkl数据已加载\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-65d9707a6ae5>:18: UserWarning: Call to deprecated function getCompleteRedYellowGreenDefinition, use getAllProgramLogics instead.\n",
      "  total_phases=traci.trafficlight.getCompleteRedYellowGreenDefinition(TL_id)[0].getPhases()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted vehicle 165 with finished traveling\n",
      "deleted vehicle 291 with finished traveling\n",
      "deleted vehicle 68 with finished traveling\n",
      "deleted vehicle 85 with finished traveling\n",
      "deleted vehicle 95 with finished traveling\n",
      "deleted vehicle 152 with finished traveling\n",
      "deleted vehicle 45 with finished traveling\n",
      "deleted vehicle 236 with finished traveling\n",
      "deleted vehicle 252 with finished traveling\n",
      "deleted vehicle 87 with finished traveling\n",
      "deleted vehicle 151 with finished traveling\n",
      "deleted vehicle 5 with finished traveling\n",
      "deleted vehicle 237 with finished traveling\n",
      "deleted vehicle 129 with finished traveling\n",
      "deleted vehicle 31 with finished traveling\n",
      "deleted vehicle 14 with finished traveling\n",
      "deleted vehicle 16 with finished traveling\n",
      "deleted vehicle 59 with finished traveling\n",
      "deleted vehicle 146 with finished traveling\n",
      "deleted vehicle 33 with finished traveling\n",
      "deleted vehicle 80 with finished traveling\n",
      "deleted vehicle 265 with finished traveling\n",
      "deleted vehicle 188 with finished traveling\n",
      "deleted vehicle 8 with finished traveling\n",
      "deleted vehicle 131 with finished traveling\n",
      "deleted vehicle 25 with finished traveling\n",
      "deleted vehicle 239 with finished traveling\n",
      "deleted vehicle 24 with finished traveling\n",
      "deleted vehicle 216 with finished traveling\n",
      "deleted vehicle 267 with finished traveling\n",
      "deleted vehicle 102 with finished traveling\n",
      "deleted vehicle 243 with finished traveling\n",
      "deleted vehicle 116 with finished traveling\n",
      "deleted vehicle 294 with finished traveling\n",
      "deleted vehicle 233 with finished traveling\n",
      "deleted vehicle 189 with finished traveling\n",
      "deleted vehicle 158 with finished traveling\n",
      "deleted vehicle 219 with finished traveling\n",
      "deleted vehicle 182 with finished traveling\n",
      "deleted vehicle 293 with finished traveling\n",
      "deleted vehicle 74 with finished traveling\n",
      "deleted vehicle 9 with finished traveling\n",
      "deleted vehicle 231 with finished traveling\n",
      "deleted vehicle 280 with finished traveling\n",
      "deleted vehicle 40 with finished traveling\n",
      "deleted vehicle 199 with finished traveling\n",
      "deleted vehicle 290 with finished traveling\n",
      "deleted vehicle 41 with finished traveling\n",
      "deleted vehicle 217 with finished traveling\n",
      "deleted vehicle 273 with finished traveling\n",
      "deleted vehicle 157 with finished traveling\n",
      "deleted vehicle 124 with finished traveling\n",
      "deleted vehicle 0 with finished traveling\n",
      "deleted vehicle 143 with finished traveling\n",
      "deleted vehicle 190 with finished traveling\n",
      "deleted vehicle 10 with finished traveling\n",
      "deleted vehicle 282 with finished traveling\n",
      "deleted vehicle 128 with finished traveling\n",
      "deleted vehicle 82 with finished traveling\n",
      "deleted vehicle 181 with finished traveling\n",
      "deleted vehicle 274 with finished traveling\n",
      "deleted vehicle 6 with finished traveling\n",
      "deleted vehicle 32 with finished traveling\n",
      "deleted vehicle 251 with finished traveling\n",
      "deleted vehicle 259 with finished traveling\n",
      "deleted vehicle 266 with finished traveling\n",
      "deleted vehicle 134 with finished traveling\n",
      "deleted vehicle 200 with finished traveling\n",
      "deleted vehicle 118 with finished traveling\n",
      "deleted vehicle 76 with finished traveling\n",
      "deleted vehicle 173 with finished traveling\n",
      "deleted vehicle 196 with finished traveling\n",
      "deleted vehicle 69 with finished traveling\n",
      "deleted vehicle 48 with finished traveling\n",
      "deleted vehicle 114 with finished traveling\n",
      "deleted vehicle 171 with finished traveling\n",
      "deleted vehicle 125 with finished traveling\n",
      "deleted vehicle 168 with finished traveling\n",
      "deleted vehicle 121 with finished traveling\n",
      "deleted vehicle 245 with finished traveling\n",
      "deleted vehicle 117 with finished traveling\n",
      "deleted vehicle 161 with finished traveling\n",
      "deleted vehicle 248 with finished traveling\n",
      "deleted vehicle 105 with finished traveling\n",
      "deleted vehicle 232 with finished traveling\n",
      "deleted vehicle 57 with finished traveling\n",
      "deleted vehicle 97 with finished traveling\n",
      "deleted vehicle 225 with finished traveling\n",
      "deleted vehicle 94 with finished traveling\n",
      "deleted vehicle 183 with finished traveling\n",
      "deleted vehicle 78 with finished traveling\n",
      "deleted vehicle 226 with finished traveling\n",
      "deleted vehicle 298 with finished traveling\n",
      "deleted vehicle 286 with finished traveling\n",
      "deleted vehicle 204 with finished traveling\n",
      "deleted vehicle 176 with finished traveling\n",
      "deleted vehicle 71 with finished traveling\n",
      "deleted vehicle 192 with finished traveling\n",
      "deleted vehicle 111 with finished traveling\n",
      "deleted vehicle 115 with finished traveling\n",
      "deleted vehicle 49 with finished traveling\n"
     ]
    },
    {
     "ename": "FatalTraCIError",
     "evalue": "Connection closed by SUMO.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFatalTraCIError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-06db8e6f2682>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;31m# 运行仿真\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[0mstart_time_global\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m \u001b[0mMPC_counter_global\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumocfg_file_global\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnet_global\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontrol_dic_global\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG_initial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets_dict_global\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtl_initialize_dic_global\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[0mend_time_global\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[0melapsed_time_global\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_time_global\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-06db8e6f2682>\u001b[0m in \u001b[0;36mrun_simulation\u001b[1;34m(sumocfg_file, net, control_dic, G_initial, targets_dict, tl_initialize_dic, random_flag)\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetRoute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicle_i_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_route\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;31m#             clear_output(wait=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulationStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[0mcurrent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SUMO\\tools\\traci\\main.py\u001b[0m in \u001b[0;36msimulationStep\u001b[1;34m(step)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[0mValues\u001b[0m \u001b[0msmaller\u001b[0m \u001b[0mthan\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mequal\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0msim\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mno\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulationStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SUMO\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36msimulationStep\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mint\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"API change now handles step as floating point seconds\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sendCmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCMD_SIMSTEP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msubscriptionResults\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subscriptionMapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0msubscriptionResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SUMO\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36m_sendCmd\u001b[1;34m(self, cmdID, varID, objID, format, *values)\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_string\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"!i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mobjID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_string\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpacked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sendExact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_readSubscription\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SUMO\\tools\\traci\\connection.py\u001b[0m in \u001b[0;36m_sendExact\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_socket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mFatalTraCIError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Connection closed by SUMO.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcommand\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"!BBB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFatalTraCIError\u001b[0m: Connection closed by SUMO."
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from collections import deque\n",
    "\n",
    "def get_edges_within_n_edges(G, start_node, n):\n",
    "    \"\"\"\n",
    "    返回从起始节点 start_node 开始，向外扩散 n 条边所涉及的所有边。\n",
    "    \n",
    "    :param G: networkx.DiGraph，有向图\n",
    "    :param start_node: 起始节点\n",
    "    :param n: 扩散的边数\n",
    "    :return: 一个列表，包含所有在 n 条边范围内的边\n",
    "    \"\"\"\n",
    "    if start_node not in G:\n",
    "        raise ValueError(f\"节点 {start_node} 不在图中\")\n",
    "\n",
    "    visited = set()  # 用于存储访问过的节点\n",
    "    edges = []  # 用于存储涉及的边\n",
    "    queue = deque([(start_node, 0)])  # 队列，存储节点和当前扩散的边数\n",
    "\n",
    "    while queue:\n",
    "        current_node, current_distance = queue.popleft()\n",
    "        \n",
    "        # 如果当前节点已经在 visited 中，跳过\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "        \n",
    "        # 标记当前节点为已访问\n",
    "        visited.add(current_node)\n",
    "        \n",
    "        # 如果当前扩散的边数已经达到 n，停止扩散\n",
    "        if current_distance == n:\n",
    "            continue\n",
    "        \n",
    "        # 将当前节点的所有邻居加入队列，并增加边数\n",
    "        for neighbor in G.successors(current_node):\n",
    "            edges.append((current_node, neighbor))  # 记录涉及的边\n",
    "            queue.append((neighbor, current_distance + 1))\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def coordinated_multi_vehicle_dynamic_routing(vehicles_all,paths_dict,G_dict): \n",
    "    # 算法2\n",
    "    vehicle_list=[]\n",
    "    action_list=[]\n",
    "    for vehicle_i in vehicles_all:\n",
    "        vehicle_list.append(vehicle_i)\n",
    "        action_list.append(list(range(0,len(paths_dict[vehicle_i]))))\n",
    "    combinations_all,_ = random_sample_action_combinations(len(vehicle_list), action_list, 100)\n",
    "    time_combinations=[]\n",
    "#     print(f\"{len(combinations_all)} combinations are sampled with {len(vehicle_list)} vehicles and action list {action_list} \")\n",
    "    for combination_i in combinations_all:\n",
    "        sum_time=0\n",
    "        for index_i in range(0,len(vehicle_list)):\n",
    "            vehicle_id=vehicle_list[index_i]\n",
    "            action_i_forward=paths_dict[vehicle_id][combination_i[index_i]]\n",
    "            action_i=list(reversed(action_i_forward))\n",
    "#             print(f\"the {index_i}th vehicle {vehicle_id} chose the {combination_i[index_i]}th path in the sampled routes{combination_i}\")\n",
    "#             print(f\"chosen path {action_i_forward}\")\n",
    "            updated_G=G_dict[vehicle_id]\n",
    "            for index_i_path in range(1,len(action_i)):\n",
    "                node_from=action_i[index_i_path]\n",
    "                node_to=action_i[index_i_path-1]\n",
    "#                 print(f\"node from {node_from} to {node_to}\")\n",
    "                sum_time=sum_time+updated_G.edges[(node_from,node_to)]['roadtime']\n",
    "        time_combinations.append(sum_time/len(vehicle_list)) # 平均时间\n",
    "    min_value = min(time_combinations)\n",
    "    min_index = time_combinations.index(min_value)\n",
    "    combination_optimal=combinations_all[min_index]\n",
    "    optimal_routes={}\n",
    "    for index_i_1 in range(0,len(vehicle_list)):\n",
    "        vehicle_i_1=vehicle_list[index_i_1]\n",
    "        optimal_routes[vehicle_i_1]=paths_dict[vehicle_i_1][combination_i[index_i_1]]\n",
    "    return optimal_routes\n",
    "def initialize_traffic_lights_randomly(tl_id):\n",
    "    \"\"\"\n",
    "    随机初始化指定交通灯的初始相位。\n",
    "    \n",
    "    参数:\n",
    "    tl_id (str): 交通灯的ID\n",
    "    \"\"\"\n",
    "    # 获取交通灯的所有相位信息\n",
    "    logics = traci.trafficlight.getAllProgramLogics(tl_id)\n",
    "    logic = logics[0]  # 获取第一个控制方案\n",
    "    phases = logic.phases  # 获取所有相位\n",
    "    \n",
    "    # 随机选择一个相位作为初始相位\n",
    "    initial_phase_index = random.randint(0, len(phases) - 1)\n",
    "    traci.trafficlight.setPhase(tl_id, initial_phase_index)\n",
    "    return initial_phase_index\n",
    "\n",
    "def initialize_traffic_lights_userdefined(tl_id,tl_initialize_dic):\n",
    "    traci.trafficlight.setPhase(tl_id, tl_initialize_dic[tl_id])\n",
    "    return tl_initialize_dic[tl_id]\n",
    "\n",
    "def run_simulation(sumocfg_file,net,control_dic,G_initial,targets_dict,tl_initialize_dic,random_flag=True):\n",
    "    \"\"\"\n",
    "    运行SUMO仿真。\n",
    "    \n",
    "    参数:\n",
    "    sumocfg_file (str): SUMO配置文件的路径\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    # 启动SUMO仿真\n",
    "#     traci.start(['sumo-gui', '-c', sumocfg_file])\n",
    "    traci.start(['sumo-gui', '-c', sumocfg_file, '--step-length', '0.1'])\n",
    "    # 获取所有交通灯的ID\n",
    "    tls_ids = traci.trafficlight.getIDList()\n",
    "    \n",
    "    # 随机初始化每个交通灯的初始相位\n",
    "    DealedTL_dic={}\n",
    "    for tl_id in tls_ids:\n",
    "        # 初始化数据字典\n",
    "        key_tl,value_tl=trafficlight_dic_generation(tl_id)\n",
    "#         print(f'trafficlight id: {tl_id}, applied id: {key_tl}')\n",
    "        DealedTL_dic[key_tl]=value_tl\n",
    "        if random_flag:\n",
    "            initialize_traffic_lights_randomly(tl_id)\n",
    "        else:\n",
    "            initialize_traffic_lights_userdefined(tl_id,tl_initialize_dic)\n",
    "    # 运行仿真\n",
    "    step = 0\n",
    "    MPC_counter=0\n",
    "    dynamic_paths={}\n",
    "    edge_id_last={}\n",
    "    G_list_distributed={}\n",
    "    while traci.simulation.getMinExpectedNumber() > 0:\n",
    "        next_target_flag=False\n",
    "        vehicles_all=traci.vehicle.getIDList()\n",
    "        # 检查所有车辆是否执行至决策点，重置对应动作\n",
    "        for vehicle_i_1 in vehicles_all:\n",
    "            edge_id_1 = traci.vehicle.getRoadID(vehicle_i_1)\n",
    "            if edge_id_1==':11_0':\n",
    "                edge_id_1='11-10'\n",
    "            elif edge_id_1==':10_8':\n",
    "                edge_id_1='10-11'\n",
    "            # 在车辆移动过程中记录实际移动的路线\n",
    "            if not edge_id_1.startswith(\":\") and (edge_id_1 not in control_dic[vehicle_i_1]['recorded route'] or edge_id_1!=edge_id_last[vehicle_i_1]):\n",
    "                control_dic[vehicle_i_1]['uk']=None\n",
    "                control_dic[vehicle_i_1]['recorded route'].append(edge_id_1)\n",
    "                edge_id_last[vehicle_i_1]=edge_id_1\n",
    "                if edge_id_1==targets_dict[vehicle_i_1][control_dic[vehicle_i_1]['stage']]:\n",
    "                    next_target_flag=True\n",
    "                    control_dic[vehicle_i_1]['stage']=control_dic[vehicle_i_1]['stage']+1\n",
    "                    # 若移动至最后一个终点路段，则视为到达终点，在调度过程中忽略该车辆\n",
    "                    if control_dic[vehicle_i_1]['stage']>=len(targets_dict[vehicle_i_1]):\n",
    "                        print(f\"deleted vehicle { vehicle_i_1} with finished traveling\")\n",
    "                        traci.vehicle.remove(vehicle_i_1)\n",
    "            else:\n",
    "                continue\n",
    "        if step % 100 == 0 or next_target_flag:\n",
    "            vehicles_all_updated=traci.vehicle.getIDList()\n",
    "            # 算法1\n",
    "            dynamic_vehicles=[]\n",
    "            for vehicle_i_2 in vehicles_all_updated:\n",
    "                edge_id_2 = traci.vehicle.getRoadID(vehicle_i_2)\n",
    "                if edge_id_2==':11_0':\n",
    "                    edge_id_2='11-10'\n",
    "                elif edge_id_2==':10_8':\n",
    "                    edge_id_2='10-11'\n",
    "                if control_dic[vehicle_i_2]['uk']==None and not edge_id_2.startswith(\":\"):\n",
    "#                     paths_i,_,path_minT=calculate_filted_path(G_initial, edge_id_2, targets_dict[vehicle_i_2][control_dic[vehicle_i_2]['stage']],1.2,6,1.2)\n",
    "                    # 更新节点属性,受限于分布式架构，对车辆i所在alpha节点而言，仅相邻Np范围内的节点信息已知\n",
    "                    G_vehicle_i=G_initial.copy()\n",
    "                    edges_vehicle_i=get_edges_within_n_edges(G_initial, edge_id_2, 2)\n",
    "                    for connection_i in edges_vehicle_i:\n",
    "                        edge_id_current=connection_i[0]\n",
    "                        vehicles_current = traci.edge.getLastStepVehicleIDs(edge_id_current)\n",
    "                        num_i=len(list(vehicles_current))\n",
    "                        C_i=G_initial.edges[connection_i]['roadlength']/(4+6)*2 # 公式（2）取2车道平均\n",
    "                        G_vehicle_i.edges[connection_i]['roadtime']=G_initial.edges[connection_i]['roadtime']*(1+0.15*(num_i/C_i)**4) #公式（1）\n",
    "                    G_list_distributed[vehicle_i_2]=G_vehicle_i\n",
    "                    paths_i,_,path_minT=calculate_filted_path(G_list_distributed[vehicle_i_2], edge_id_2, targets_dict[vehicle_i_2][control_dic[vehicle_i_2]['stage']],1,0,1)\n",
    "                    dynamic_paths[vehicle_i_2]=[path_minT]\n",
    "#                     print(f\"vehicle {vehicle_i_2} generated paths {paths_i}\")\n",
    "                    dynamic_vehicles.append(vehicle_i_2)\n",
    "                else:\n",
    "                    continue\n",
    "            if len(dynamic_vehicles)>0:\n",
    "                optimal_routes=coordinated_multi_vehicle_dynamic_routing(dynamic_vehicles,dynamic_paths,G_list_distributed)\n",
    "#                 print(f\"vehicles {dynamic_vehicles} are cooperating for dynamic routes\")\n",
    "                MPC_counter=MPC_counter+1\n",
    "            # 执行决策动作\n",
    "            for vehicle_i_3 in dynamic_vehicles:\n",
    "                edge_id_3 = traci.vehicle.getRoadID(vehicle_i_3)\n",
    "                current_route=optimal_routes[vehicle_i_3]\n",
    "                if edge_id_3==':11_0':\n",
    "                    edge_id_3='11-10'\n",
    "                elif edge_id_3==':10_8':\n",
    "                    edge_id_3='10-11'\n",
    "                traci.vehicle.setRoute(vehicle_i_3, current_route)\n",
    "#             clear_output(wait=True)\n",
    "        traci.simulationStep()\n",
    "        current_time = traci.simulation.getTime()\n",
    "        step += 1\n",
    "    end_time = time.time()      \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"耗时{elapsed_time}秒\")\n",
    "    # 关闭TraCI连接\n",
    "    traci.close()\n",
    "    print(f\"SUMO终端已关闭\")\n",
    "    return MPC_counter\n",
    "\n",
    "# 选择初始相位数据组\n",
    "simulating_data_index=14\n",
    "\n",
    "\n",
    "#初始化图\n",
    "net_global = sumolib.net.readNet(\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\sourceCICT.net.xml\")\n",
    "G_initial=convert_net_to_digraph_simple(net_global)\n",
    "seleted_indexes_list_global=database_baseline['Routes index list']\n",
    "# print(seleted_indexes_list)\n",
    "G_total_dict_global={}\n",
    "targets_dict_global={}\n",
    "vehicle_ids_global=[]\n",
    "DJT_dict_global={}\n",
    "for iteration_index_global in range(len(seleted_indexes_list_global)):\n",
    "    vehicle_index_global=seleted_indexes_list_global[iteration_index_global]\n",
    "    vehicle_id_global=str(iteration_index_global)\n",
    "    current_data_index_global=seleted_indexes_list_global[vehicle_index_global]\n",
    "    G_list_global=database_dic[vehicle_index_global]['Graph list']\n",
    "    G_total_dict_global[vehicle_id_global]=G_list_global\n",
    "    indexed_target_single_global=database_dic[vehicle_index_global]['Indexed Targets']\n",
    "    targets_dict_global[vehicle_id_global]=indexed_target_single_global\n",
    "    vehicle_ids_global.append(vehicle_id_global)  \n",
    "    DJTpath_single_forward=database_dic[vehicle_index_global]['Possible DJT']\n",
    "    DJT_dic_single={}\n",
    "    DJT_dic_single['path']=DJTpath_single_forward\n",
    "    DJT_dic_single['length']={}\n",
    "    length_all=0\n",
    "    DJTpath_single=list(reversed(DJTpath_single_forward))\n",
    "    for index_i_path in range(1,len(DJTpath_single)):\n",
    "        node_i_path_from=DJTpath_single[index_i_path]\n",
    "        node_i_path_to=DJTpath_single[index_i_path-1]\n",
    "        DJT_dic_single['length'][node_i_path_from]=length_all\n",
    "        length_all=length_all+G_initial.edges[(node_i_path_from,node_i_path_to)]['roadlength']\n",
    "    DJT_dict_global[vehicle_id_global]=DJT_dic_single\n",
    "    \n",
    "\n",
    "\n",
    "control_dic_global=control_dictionary_initialize(G_total_dict_global,targets_dict_global,vehicle_ids_global)\n",
    "# 交通灯初始配置\n",
    "# output_path_config_global= r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases2.pkl\" \n",
    "output_path_config_global= f\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\InitialPhases{simulating_data_index}.pkl\"\n",
    "with open(output_path_config_global, 'rb') as file:\n",
    "    tl_initialize_dic_global = pickle.load(file)\n",
    "print(f\"{output_path_config_global}数据已加载\")\n",
    "# SUMO配置文件路径\n",
    "sumocfg_file_global = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\baseline_DJL.sumocfg\"\n",
    "# 运行仿真\n",
    "start_time_global = time.time()\n",
    "MPC_counter_global=run_simulation(sumocfg_file_global,net_global,control_dic_global,G_initial,targets_dict_global,tl_initialize_dic_global,False)\n",
    "end_time_global = time.time()      \n",
    "elapsed_time_global = end_time_global - start_time_global\n",
    "print(f\"{len(seleted_indexes_list_global)}辆规模，{MPC_counter_global}车次动态调度，共运行耗时：{elapsed_time_global}\")\n",
    "output_file_path_global = r\"D:\\\\SUMO\\\\work\\\\rebuild2\\\\route_CCDR.pkl\"  # 替换为你想要保存的文件名\n",
    "with open(output_file_path_global, 'wb') as file:\n",
    "    pickle.dump(control_dic_global, file)\n",
    "print(f\"数据已保存到：{output_file_path_global}\")\n",
    "\n",
    "# 结果数据储存\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# 定义文件夹名称和文件路径\n",
    "folder_name = f\"CCDR_DJLBased_result{simulating_data_index}\"  # 新建的文件夹名称\n",
    "files_to_move =['fcd_DJL.xml','queue_DJL.xml','recorded_route_DJL.xml'] # 要移动的文件名称\n",
    "source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\" # 源文件夹路径\n",
    "address = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\"  # 新建文件夹的路径\n",
    "\n",
    "# 创建目标文件夹（如果文件夹不存在）\n",
    "target_folder = os.path.join(address, folder_name)\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "    print(f\"文件夹 '{target_folder}' 创建成功。\")\n",
    "else:\n",
    "    print(f\"文件夹 '{target_folder}' 已存在。\")\n",
    "\n",
    "# 移动文件\n",
    "for file_name in files_to_move:\n",
    "    source_path = os.path.join(source_folder, file_name)  # 源文件路径\n",
    "    destination_path = os.path.join(target_folder, file_name)  # 目标文件路径\n",
    "\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.move(source_path, destination_path)\n",
    "        print(f\"文件 '{file_name}' 已成功从 '{source_folder}' 移入文件夹 '{target_folder}'。\")\n",
    "    else:\n",
    "        print(f\"文件 '{file_name}' 在 '{source_folder}' 中不存在，无法移动。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO终端已关闭\n"
     ]
    }
   ],
   "source": [
    "# 关闭TraCI连接\n",
    "traci.close()\n",
    "print(\"SUMO终端已关闭\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果转译为.rou.xml文件以便于复现，并核验结果路由"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，新的文件已保存为 D:\\SUMO\\work\\rebuild2\\DMPC_DJLBased_result14\\route_DMPC.rou.xml\n",
      "处理完成，文件已复制到 D:\\SUMO\\work\\rebuild2\\route_DMPC.rou.xml\n",
      "核验通过，所有车辆均成功依次经过了所有目标\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import shutil\n",
    "\n",
    "simulating_data_index=14\n",
    "folder_name = f\"DMPC_DJLBased_result{simulating_data_index}\" \n",
    "source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\" # 源文件夹路径\n",
    "target_folder = os.path.join(source_folder, folder_name)\n",
    "source_file = os.path.join(target_folder, 'recorded_route_DJL.xml')\n",
    "target_file=os.path.join(target_folder, 'route_DMPC.rou.xml')\n",
    "# 指定文件路径\n",
    "address_A = source_file\n",
    "address_B = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\route_DJL.rou.xml\"\n",
    "address_output = target_file\n",
    "\n",
    "# 读取并解析 A.rou.xml 文件\n",
    "tree_A = ET.parse(address_A)\n",
    "root_A = tree_A.getroot()\n",
    "\n",
    "# 读取并解析 B.rou.xml 文件\n",
    "tree_B = ET.parse(address_B)\n",
    "root_B = tree_B.getroot()\n",
    "\n",
    "# 创建一个字典来存储 A 文件中每个车辆的 <routeDistribution> 信息\n",
    "route_distribution_dict = {}\n",
    "for vehicle in root_A.findall('vehicle'):\n",
    "    vehicle_id = vehicle.get(\"id\")\n",
    "    route_distribution = vehicle.find(\"routeDistribution\")\n",
    "    if route_distribution is not None:\n",
    "        route_distribution_dict[vehicle_id] = route_distribution\n",
    "\n",
    "# 遍历 B 文件中的车辆，并替换 <route> 信息\n",
    "for vehicle in root_B.findall('vehicle'):\n",
    "    vehicle_id = vehicle.get(\"id\")\n",
    "    if vehicle_id in route_distribution_dict:\n",
    "        # 删除原有的 <route> 元素\n",
    "        for route in vehicle.findall(\"route\"):\n",
    "            vehicle.remove(route)\n",
    "        # 添加新的 <routeDistribution> 元素\n",
    "        vehicle.append(route_distribution_dict[vehicle_id])\n",
    "        \n",
    "# # 创建一个字典来存储 A 文件中每个车辆的最后一个 route 的 edges 信息\n",
    "# route_dict = {}\n",
    "# for vehicle in root_A.findall('vehicle'):\n",
    "#     vehicle_id = vehicle.get(\"id\")\n",
    "#     route_distribution = vehicle.find(\"routeDistribution\")\n",
    "#     if route_distribution is not None:\n",
    "#         # 获取最后一个 route 的 edges\n",
    "#         last_route = route_distribution.findall(\"route\")[-1]\n",
    "#         route_edges = last_route.get(\"edges\")\n",
    "#         route_dict[vehicle_id] = route_edges\n",
    "\n",
    "# # 遍历 B 文件中的车辆，并替换路线信息\n",
    "# for vehicle in root_B.findall('vehicle'):\n",
    "#     vehicle_id = vehicle.get(\"id\")\n",
    "#     if vehicle_id in route_dict:\n",
    "#         route = vehicle.find(\"route\")\n",
    "#         if route is not None:\n",
    "#             route.set(\"edges\", route_dict[vehicle_id])\n",
    "\n",
    "# 将修改后的 XML 写入新的文件\n",
    "# 使用 minidom 来美化输出\n",
    "rough_string = ET.tostring(root_B, 'utf-8')\n",
    "reparsed = minidom.parseString(rough_string)\n",
    "pretty_xml_as_string = reparsed.toprettyxml(indent=\"    \")\n",
    "\n",
    "with open(address_output, 'w', encoding='utf-8') as f:\n",
    "    f.write(pretty_xml_as_string)\n",
    "\n",
    "print(f\"处理完成，新的文件已保存为 {address_output}\")\n",
    "\n",
    "# 源文件路径\n",
    "# 目标文件路径（或目录）\n",
    "destination =os.path.join(source_folder, 'route_DMPC.rou.xml')  # 或 'path/to/destination_directory/'\n",
    "\n",
    "shutil.copy(target_file, destination)\n",
    "print(f\"处理完成，文件已复制到 {destination}\")\n",
    "\n",
    "# 检查终点是否都在路径结果内\n",
    "seleted_indexes_list_global=database_baseline['Routes index list']\n",
    "targets_dict_global={}\n",
    "total_pass_flag=True\n",
    "for iteration_index_global in range(len(seleted_indexes_list_global)):\n",
    "    vehicle_index_global=seleted_indexes_list_global[iteration_index_global]\n",
    "    vehicle_id_global=str(iteration_index_global)\n",
    "    indexed_target_single_global=database_dic[vehicle_index_global]['Indexed Targets']\n",
    "    targets_dict_global[vehicle_id_global]=indexed_target_single_global\n",
    "    check_pass_flag=True\n",
    "    for i in indexed_target_single_global:\n",
    "        if i not in route_dict[vehicle_id_global]:\n",
    "            check_pass_flag=False\n",
    "            break\n",
    "    if not check_pass_flag:\n",
    "        total_pass_flag=False\n",
    "        print(f\"核验失败，车辆 {vehicle_id_global} 在目标{indexed_target_single_global}中未经过目标{i}\")\n",
    "if total_pass_flag:\n",
    "    print(f\"核验通过，所有车辆均成功依次经过了所有目标\")\n",
    "else:\n",
    "    print(f\"核验失败，存在车辆未依次经过所有目标\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，新的文件已保存为 D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result18\\route_DMPC.rou.xml\n",
      "处理完成，文件已复制到 D:\\SUMO\\work\\rebuild2\\route_DMPC.rou.xml\n",
      "核验通过，所有车辆均成功依次经过了所有目标\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import shutil\n",
    "\n",
    "simulating_data_index=18\n",
    "folder_name = f\"CCDR_DJLBased_result{simulating_data_index}\" \n",
    "source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\" # 源文件夹路径\n",
    "target_folder = os.path.join(source_folder, folder_name)\n",
    "source_file = os.path.join(target_folder, 'recorded_route_DJL.xml')\n",
    "target_file=os.path.join(target_folder, 'route_DMPC.rou.xml')\n",
    "# 指定文件路径\n",
    "address_A = source_file\n",
    "address_B = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\route_DJL.rou.xml\"\n",
    "address_output = target_file\n",
    "\n",
    "# 读取并解析 A.rou.xml 文件\n",
    "tree_A = ET.parse(address_A)\n",
    "root_A = tree_A.getroot()\n",
    "\n",
    "# 读取并解析 B.rou.xml 文件\n",
    "tree_B = ET.parse(address_B)\n",
    "root_B = tree_B.getroot()\n",
    "\n",
    "# # 创建一个字典来存储 A 文件中每个车辆的 <routeDistribution> 信息\n",
    "# route_distribution_dict = {}\n",
    "# for vehicle in root_A.findall('vehicle'):\n",
    "#     vehicle_id = vehicle.get(\"id\")\n",
    "#     route_distribution = vehicle.find(\"routeDistribution\")\n",
    "#     if route_distribution is not None:\n",
    "#         route_distribution_dict[vehicle_id] = route_distribution\n",
    "\n",
    "# # 遍历 B 文件中的车辆，并替换 <route> 信息\n",
    "# for vehicle in root_B.findall('vehicle'):\n",
    "#     vehicle_id = vehicle.get(\"id\")\n",
    "#     if vehicle_id in route_distribution_dict:\n",
    "#         # 删除原有的 <route> 元素\n",
    "#         for route in vehicle.findall(\"route\"):\n",
    "#             vehicle.remove(route)\n",
    "#         # 添加新的 <routeDistribution> 元素\n",
    "#         vehicle.append(route_distribution_dict[vehicle_id])\n",
    "        \n",
    "# 创建一个字典来存储 A 文件中每个车辆的最后一个 route 的 edges 信息\n",
    "route_dict = {}\n",
    "for vehicle in root_A.findall('vehicle'):\n",
    "    vehicle_id = vehicle.get(\"id\")\n",
    "    route_distribution = vehicle.find(\"routeDistribution\")\n",
    "    if route_distribution is not None:\n",
    "        # 获取最后一个 route 的 edges\n",
    "        last_route = route_distribution.findall(\"route\")[-1]\n",
    "        route_edges = last_route.get(\"edges\")\n",
    "        route_dict[vehicle_id] = route_edges\n",
    "\n",
    "# 遍历 B 文件中的车辆，并替换路线信息\n",
    "for vehicle in root_B.findall('vehicle'):\n",
    "    vehicle_id = vehicle.get(\"id\")\n",
    "    if vehicle_id in route_dict:\n",
    "        route = vehicle.find(\"route\")\n",
    "        if route is not None:\n",
    "            route.set(\"edges\", route_dict[vehicle_id])\n",
    "\n",
    "# 将修改后的 XML 写入新的文件\n",
    "# 使用 minidom 来美化输出\n",
    "rough_string = ET.tostring(root_B, 'utf-8')\n",
    "reparsed = minidom.parseString(rough_string)\n",
    "pretty_xml_as_string = reparsed.toprettyxml(indent=\"    \")\n",
    "\n",
    "with open(address_output, 'w', encoding='utf-8') as f:\n",
    "    f.write(pretty_xml_as_string)\n",
    "\n",
    "print(f\"处理完成，新的文件已保存为 {address_output}\")\n",
    "\n",
    "# 源文件路径\n",
    "# 目标文件路径（或目录）\n",
    "destination =os.path.join(source_folder, 'route_DMPC.rou.xml')  # 或 'path/to/destination_directory/'\n",
    "\n",
    "shutil.copy(target_file, destination)\n",
    "print(f\"处理完成，文件已复制到 {destination}\")\n",
    "\n",
    "# 检查终点是否都在路径结果内\n",
    "seleted_indexes_list_global=database_baseline['Routes index list']\n",
    "targets_dict_global={}\n",
    "total_pass_flag=True\n",
    "for iteration_index_global in range(len(seleted_indexes_list_global)):\n",
    "    vehicle_index_global=seleted_indexes_list_global[iteration_index_global]\n",
    "    vehicle_id_global=str(iteration_index_global)\n",
    "    indexed_target_single_global=database_dic[vehicle_index_global]['Indexed Targets']\n",
    "    targets_dict_global[vehicle_id_global]=indexed_target_single_global\n",
    "    check_pass_flag=True\n",
    "    for i in indexed_target_single_global:\n",
    "        if i not in route_dict[vehicle_id_global]:\n",
    "            check_pass_flag=False\n",
    "            break\n",
    "    if not check_pass_flag:\n",
    "        total_pass_flag=False\n",
    "        print(f\"核验失败，车辆 {vehicle_id_global} 在目标{indexed_target_single_global}中未经过目标{i}\")\n",
    "if total_pass_flag:\n",
    "    print(f\"核验通过，所有车辆均成功依次经过了所有目标\")\n",
    "else:\n",
    "    print(f\"核验失败，存在车辆未依次经过所有目标\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据转化为excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "\n",
    "# 读取xml文件，写入excel\n",
    "def xmlToExcel(file_xml, file_excel):\n",
    "    # 创建一个excel文件，并添加一个sheet，命名为orders\n",
    "    workbook = xlsxwriter.Workbook(file_excel)\n",
    "    sheet = workbook.add_worksheet('orders')\n",
    "    # 设置粗体\n",
    "    bold = workbook.add_format({'bold': True})\n",
    "    # 先在第一行写标题，用粗体\n",
    "    sheet.write('A1', u'time', bold)\n",
    "    sheet.write('B1', u'id', bold)\n",
    "    sheet.write('C1', u'x', bold)\n",
    "    sheet.write('D1', u'y', bold)\n",
    "    sheet.write('E1', u'angle', bold)\n",
    "    sheet.write('F1', u'speed', bold)\n",
    "    sheet.write('G1', u'lane', bold)\n",
    "    sheet.write('H1', u'pos', bold)\n",
    "    \n",
    "    # 从第二行开始录入数据\n",
    "    row = 1  # 从第一行的下一行开始写入数据\n",
    "\n",
    "    # 使用 iterparse 逐行解析 XML 文件\n",
    "    for event, elem in ET.iterparse(file_xml, events=('end',)):\n",
    "        if elem.tag == 'timestep':\n",
    "            time = elem.get('time')\n",
    "            if row % 1000 ==0:\n",
    "                print(f\"time {time} writing\")\n",
    "            for vehicle in elem.findall('vehicle'):\n",
    "                vehicle_id = vehicle.get('id')\n",
    "                x_num = vehicle.get('x')\n",
    "                y_num = vehicle.get('y')\n",
    "                angle = vehicle.get('angle')\n",
    "                speed = vehicle.get('speed')\n",
    "                lane = vehicle.get('lane')\n",
    "                pos = vehicle.get('pos')\n",
    "                # 将每个timestep中车辆数据写入excel中\n",
    "                sheet.write(row, 0, time)\n",
    "                sheet.write(row, 1, vehicle_id)\n",
    "                sheet.write(row, 2, x_num)\n",
    "                sheet.write(row, 3, y_num)\n",
    "                sheet.write(row, 4, angle)\n",
    "                sheet.write(row, 5, speed)\n",
    "                sheet.write(row, 6, lane)\n",
    "                sheet.write(row, 7, pos)\n",
    "                row += 1\n",
    "            # 清理已完成的元素，释放内存\n",
    "            elem.clear()\n",
    "\n",
    "    # 关闭文件\n",
    "    workbook.close()\n",
    "\n",
    "# 设置文件路径\n",
    "simulating_data_index = 4\n",
    "folder_name = f\"DMPC_DJLBased_result{simulating_data_index}\"\n",
    "source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\"  # 源文件夹路径\n",
    "target_folder = os.path.join(source_folder, folder_name)\n",
    "xml_file_path = os.path.join(target_folder, 'fcd_DJL.xml')\n",
    "excel_file_path = os.path.join(target_folder, 'fcd_total.xlsx')  # 输出Excel文件路径\n",
    "\n",
    "# 调用函数\n",
    "print(\"converting\")\n",
    "xmlToExcel(xml_file_path, excel_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result2\\fcd_DJL.xml converting\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result2\\fcd_DJL.xml converted\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result4\\fcd_DJL.xml converting\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result4\\fcd_DJL.xml converted\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result7\\fcd_DJL.xml converting\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result7\\fcd_DJL.xml converted\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result14\\fcd_DJL.xml converting\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result14\\fcd_DJL.xml converted\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result18\\fcd_DJL.xml converting\n",
      "D:\\SUMO\\work\\rebuild2\\CCDR_DJLBased_result18\\fcd_DJL.xml converted\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "\n",
    "# 读取xml文件，写入excel\n",
    "def xmlToExcel(file_xml, file_excel):\n",
    "    # 创建一个excel文件，并添加一个sheet，命名为orders\n",
    "    workbook = xlsxwriter.Workbook(file_excel)\n",
    "    sheet = workbook.add_worksheet('orders')\n",
    "    # 设置粗体\n",
    "    bold = workbook.add_format({'bold': True})\n",
    "    # 先在第一行写标题，用粗体\n",
    "    sheet.write('A1', u'time', bold)\n",
    "    sheet.write('B1', u'id', bold)\n",
    "    sheet.write('C1', u'x', bold)\n",
    "    sheet.write('D1', u'y', bold)\n",
    "    sheet.write('E1', u'angle', bold)\n",
    "    sheet.write('F1', u'speed', bold)\n",
    "    sheet.write('G1', u'lane', bold)\n",
    "    sheet.write('H1', u'pos', bold)\n",
    "    \n",
    "    # 从第二行开始录入数据\n",
    "    row = 1  # 从第一行的下一行开始写入数据\n",
    "\n",
    "    # 使用 iterparse 逐行解析 XML 文件\n",
    "    for event, elem in ET.iterparse(file_xml, events=('end',)):\n",
    "        if elem.tag == 'timestep':\n",
    "            time = elem.get('time')\n",
    "#             if row % 1000 ==0:\n",
    "#                 print(f\"time {time} writing\")\n",
    "            for vehicle in elem.findall('vehicle'):\n",
    "                vehicle_id = vehicle.get('id')\n",
    "                x_num = vehicle.get('x')\n",
    "                y_num = vehicle.get('y')\n",
    "                angle = vehicle.get('angle')\n",
    "                speed = vehicle.get('speed')\n",
    "                lane = vehicle.get('lane')\n",
    "                pos = vehicle.get('pos')\n",
    "                # 将每个timestep中车辆数据写入excel中\n",
    "                sheet.write(row, 0, time)\n",
    "                sheet.write(row, 1, vehicle_id)\n",
    "                sheet.write(row, 2, x_num)\n",
    "                sheet.write(row, 3, y_num)\n",
    "                sheet.write(row, 4, angle)\n",
    "                sheet.write(row, 5, speed)\n",
    "                sheet.write(row, 6, lane)\n",
    "                sheet.write(row, 7, pos)\n",
    "                row += 1\n",
    "            # 清理已完成的元素，释放内存\n",
    "            elem.clear()\n",
    "\n",
    "    # 关闭文件\n",
    "    workbook.close()\n",
    "\n",
    "indexes_select=[2,4,7,14,18]\n",
    "for simulating_data_index in indexes_select:\n",
    "    # 设置文件路径\n",
    "    # simulating_data_index = 9\n",
    "    folder_name = f\"CCDR_DJLBased_result{simulating_data_index}\"\n",
    "    source_folder = \"D:\\\\SUMO\\\\work\\\\rebuild2\\\\\"  # 源文件夹路径\n",
    "    target_folder = os.path.join(source_folder, folder_name)\n",
    "    xml_file_path = os.path.join(target_folder, 'fcd_DJL.xml')\n",
    "    excel_file_path = os.path.join(target_folder, 'fcd_total.xlsx')  # 输出Excel文件路径\n",
    "\n",
    "    # 调用函数\n",
    "    print(f\"{xml_file_path} converting\")\n",
    "    xmlToExcel(xml_file_path, excel_file_path) \n",
    "    print(f\"{xml_file_path} converted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据转化为.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\SUMO\\work\\DMPC_DJLBased_result14111\\fcd_DJL.xml converted\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xlsxwriter\n",
    "import os\n",
    "from scipy.io import savemat\n",
    "\n",
    "# 读取xml文件，写入excel\n",
    "def datadeal(file_xml):\n",
    "    vehicle_indicator={}\n",
    "    vehicle_dataframe={}\n",
    "    frame_indicator={}\n",
    "    vehicle_set=set()\n",
    "    for event, elem in ET.iterparse(file_xml, events=('end',)):\n",
    "        if elem.tag == 'timestep':\n",
    "            time = elem.get('time')\n",
    "            if float(time)%500==0:\n",
    "                print(f\"processing time {time}\")\n",
    "            vehicle_num_current=0\n",
    "            vehicle_speed_current=0\n",
    "            for vehicle in elem.findall('vehicle'):\n",
    "                vehicle_id = vehicle.get('id')\n",
    "                if vehicle_id not in vehicle_set:\n",
    "                    vehicle_set.add(vehicle_id)\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']={}\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['time']=[]\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['x']=[]\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['y']=[]\n",
    "                    vehicle_dataframe[f'vehicle_{vehicle_id}']['speed']=[]\n",
    "                x_num = vehicle.get('x')\n",
    "                y_num = vehicle.get('y')\n",
    "                speed = vehicle.get('speed')\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['time'].append(float(time))\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['x'].append(float(x_num))\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['y'].append(float(y_num))\n",
    "                vehicle_dataframe[f'vehicle_{vehicle_id}']['speed'].append(float(speed))\n",
    "                vehicle_num_current=vehicle_num_current+1\n",
    "                vehicle_speed_current=vehicle_speed_current+float(speed)\n",
    "            frame_indicator[f'time_{int(float(time)*1000)}_ms']=np.array([vehicle_num_current,vehicle_speed_current/max(vehicle_num_current,1)])\n",
    "            elem.clear()\n",
    "    for vehicle_id_ind in vehicle_dataframe:\n",
    "        start_time=min(vehicle_dataframe[vehicle_id_ind]['time'])\n",
    "        end_time=max(vehicle_dataframe[vehicle_id_ind]['time'])\n",
    "        total_speed=sum(vehicle_dataframe[vehicle_id_ind]['speed'])\n",
    "        x_list=vehicle_dataframe[vehicle_id_ind]['x']\n",
    "        diff_x=[x_list[i+1] - x_list[i] for i in range(len(x_list) - 1)]\n",
    "        y_list=vehicle_dataframe[vehicle_id_ind]['y']\n",
    "        diff_y=[y_list[i+1] - y_list[i] for i in range(len(y_list) - 1)]\n",
    "        distance_step=[a**2 + b**2 for a, b in zip(diff_x, diff_y)]\n",
    "        vehicle_indicator[vehicle_id_ind]={}\n",
    "        vehicle_indicator[vehicle_id_ind]['appear']=start_time\n",
    "        vehicle_indicator[vehicle_id_ind]['disappear']=end_time\n",
    "        vehicle_indicator[vehicle_id_ind]['distance']=sum(distance_step)\n",
    "        vehicle_indicator[vehicle_id_ind]['averaspeed']=sum(distance_step)/(end_time-start_time)\n",
    "        vehicle_dataframe[vehicle_id_ind]['time']=np.array(vehicle_dataframe[vehicle_id_ind]['time'])\n",
    "        vehicle_dataframe[vehicle_id_ind]['x']=np.array(vehicle_dataframe[vehicle_id_ind]['x'])\n",
    "        vehicle_dataframe[vehicle_id_ind]['y']=np.array(vehicle_dataframe[vehicle_id_ind]['y'])\n",
    "        vehicle_dataframe[vehicle_id_ind]['speed']=np.array(vehicle_dataframe[vehicle_id_ind]['speed'])\n",
    "\n",
    "    # 关闭文件\n",
    "    return vehicle_indicator,frame_indicator,vehicle_dataframe\n",
    "# indexes_select=[11111,21111,31111,12111,13111,14111,11211,11311,11411,11121,11131,11112,11113]\n",
    "indexes_select=[12111,13111,14111]\n",
    "full_dealed_data={}\n",
    "for simulating_data_index in indexes_select:\n",
    "    # 设置文件路径\n",
    "    # simulating_data_index = 9\n",
    "    folder_name = f\"DMPC_DJLBased_result{simulating_data_index}\"\n",
    "    # folder_name = f\"CCDR_DJLBased_result{simulating_data_index}\"\n",
    "    source_folder = \"D:\\\\SUMO\\\\work\\\\\"  # 源文件夹路径\n",
    "    target_folder = os.path.join(source_folder, folder_name)\n",
    "    xml_file_path = os.path.join(target_folder, 'fcd_DJL.xml')\n",
    "    # 调用函数\n",
    "    print(f\"{xml_file_path} converting\")\n",
    "    vehicle_indicator,frame_indicator,vehicle_dataframe=datadeal(xml_file_path)\n",
    "    full_dealed_data[f'file_{simulating_data_index}']={}\n",
    "    full_dealed_data[f'file_{simulating_data_index}']['vehicle_indicator']=vehicle_indicator\n",
    "    full_dealed_data[f'file_{simulating_data_index}']['frame_indicator']=frame_indicator\n",
    "    full_dealed_data[f'file_{simulating_data_index}']['dataframes']=vehicle_dataframe\n",
    "    clear_output(wait=True)\n",
    "    single_dealed_data={}\n",
    "    single_dealed_data['vehicle_indicator']=vehicle_indicator\n",
    "    single_dealed_data['frame_indicator']=frame_indicator\n",
    "    single_dealed_data['dataframes']=vehicle_dataframe\n",
    "    with open(f\"D:\\\\SUMO\\\\work\\\\DMPC_data_{simulating_data_index}.pkl\", 'wb') as file:\n",
    "    # with open(f\"D:\\\\SUMO\\\\work\\\\CCDR_data_{simulating_data_index}.pkl\", 'wb') as file:\n",
    "        pickle.dump(single_dealed_data, file)\n",
    "    print(f\"{xml_file_path} converted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
